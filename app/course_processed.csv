COURSE_ID,TITLE,DESCRIPTION
ML0201EN,robots are coming  build iot apps with watson  swift  and node red,have fun with iot and learn along the way  if you re a swift developer and want to learn more about iot and watson ai services in the cloud  raspberry pi   and node red  you ve found the right place  you ll build iot apps to read temperature data  take pictures with a raspcam  use ai to recognize the objects in those pictures  and program an irobot create 2 robot  
ML0122EN,accelerating deep learning with gpu,"training complex deep learning models with large datasets takes along time  in this course  you will learn how to use accelerated gpu hardware to overcome the scalability problem in deep learning 
you can use accelerated hardware such as google s tensor processing unit  tpu  or nvidia gpu to accelerate your convolutional neural network computations time on the cloud  these chips are specifically designed to support the training of neural networks  as well as the use of trained networks  inference   accelerated hardware has recently been proven to significantly reduce training time 
but the problem is that your data might be sensitiveand you may not feel comfortable uploading it on a public cloud  preferring to analyze it on premise  in this case  you need to use an in house system with gpu support  one solution is to use ibm s power systems with nvidia gpu and power ai  the power ai platform supports popular machine learning libraries and dependencies including tensorflow  caffe  torch  and theano 
in this course  you ll understand what gpu based accelerated hardware is and how it can benefit your deep learning scaling needs  you ll also deploy deep learning networks on gpu accelerated hardware for several problems  including the classification of images and videos "
GPXX0ZG0EN,consuming restful services using the reactive jax rs client,learn how to use a reactive jax rs client to asynchronously invoke restful microservices over http 
RP0105EN,analyzing big data in r using apache spark,"apache spark is a popular cluster computing framework used for performing large scale data analysis  sparkr provides a distributed data frame api that enables structured data processing with a syntax familiar to r users 
"
GPXX0Z2PEN,containerizing  packaging  and running a spring boot application,learn how to containerize  package  and run a spring boot application on an open liberty server without modification 
CNSC02EN,cloud native security conference   data security,introduction to data security on cloud
DX0106EN,data science bootcamp with r for university proffesors,a multi day intensive  in person data science bootcamp offered by big data university
GPXX0FTCEN,learn how to use docker containers for iterative development,learn how to use docker containers for iterative development 
RAVSCTEST1,scorm test 1,scron test course
GPXX06RFEN,create your first mongodb database,in this guided project  you will get started with mongodb by creating your first database  working with collections  and doing basic document management  
GPXX0SDXEN,testing microservices with the arquillian managed container,learn how to develop tests for your microservices with the arquillian managed container and run the tests on open liberty 
CC0271EN,cloud pak for integration essentials,in this short course  you will demonstrate the hands on experience with a comprehensive cloud integration solution using ibm cloud pak for integration that you received from attending the digital developer conference  aiops   integration  
WA0103EN,watson analytics for social media,watson analytics for social media fundamentals teaches you the basics of watson analytics for social media on the cloud   in this course you will learn how to setup a project to analyze social data within watson analytics   you will learn how smart topic suggestions service enables you to refine and improve your project   you will learn about how about the base line reports with watson analytics for social media as well as how you can further use the dataset in watson analytics explore and assemble   
DX0108EN,data science bootcamp with python for university professors  advance ,data science bootcamp with python for university professors  advance 
GPXX0PICEN,create a cryptocurrency trading algorithm in python,earning money while you sleep  that may sound too good to be true  but with the right cryptocurrency trading algorithm you can do just that  in this project  you will take a first dive into the world of algorithmic trading with python 
DAI101EN,data   ai essentials,data and ai essentials course
GPXX0W7KEN,securing java microservices with eclipse microprofile json web token  microprofile jwt ,you will explore how to control user and role access to microservices with microprofile json web token  microprofile jwt  
GPXX0QR3EN,enabling distributed tracing in microservices with zipkin,explore how to enable and customize tracing of jax rs and non jax rs methods by using microprofile opentracing and the zipkin tracing system 
BD0145EN,sql access for hadoop,"big sql is another tool to work with your hadoop data  big sql provides a common and familiar syntax for those that are already using sql with their relational data to work with their big data  there is no learning curve here  big sql is about applying sql to your existing data ‚äì there are no proprietary storage formats 

this course will help you understand the big sql architecture and show the different methods for working with big sql  the course will list and explain the big sql data types and show how to create big sql schemas and table  the course will also cover the different file formats supported by big sql such as parquet and orc 
in the lab exercises  you will get a chance to learn how to connect to the big sql server and load in some sample data  then you will see how easy it is to use big sql to work with the data "
HCC105EN,hybrid cloud conference  ai pipelines lab,hybrid cloud conference  ai pipelines lab
DE0205EN,dataops methodology,data ops course
DS0132EN,data   ai  jumpstart your journey,introduce you to data and ai
OS0101EN,introduction to open source,this course introduces you to open source software  you ll learn the key concepts  tools  and processes to contribute to any open source project 
DS0201EN,end to end data science on cloudpak for data,end to end data science on cloudpak for data
BENTEST4,ai for everyone  master the basics,learn what artificial intelligence  ai  is by understanding its applications and key concepts including machine learning  deep learning and neural networks 
CC0210EN,serverless computing using cloud functions   developer i,this course is designed to teach you serverless computing essentials which include how to develop serverless applications composed of loosely coupled  microservice like functions  
PA0103EN,predicting customer satisfaction,predict customer satisfactions with machine learning moddels
HCC104EN,hybrid cloud conference serverless lab,hybrid cloud conference serverless lab
GPXX0A1YEN,validating constraints for javabeans in java microservices,explore the use of bean validation to validate user input data for microservices 
TMP0105EN,getting started with the data  apache spark makers build,"apache spark is an open source processing engine built around speed  ease of use  and analytics  if you have large amounts of data that requires low latency processing that a typical map reduce program cannot provide  spark is the alternative  spark performs at speeds up to 100 times faster than map reduce for iterative algorithms or interactive data mining  spark provides in memory cluster computing for lightning fast speed and supports java  scala  and python apis for ease of development 

spark combines sql  streaming and complex analytics together seamlessly in the same application to handle a wide range of data processing scenarios  spark runs on top of hadoop  mesos  standalone  or in the cloud  it can access diverse data sources such as hdfs  cassandra  hbase  or s3 "
PA0107EN,predicting financial performance of a company,predict financial performance of a company using machine learning models
DB0113EN,db2 fundamentals i,db2 database course
PA0109EN,using clustering methods for investment portfolio analysis,using clustering methods for investment portfolio analysis
PHPM002EN,php web application on a lamp stack,this tutorial walks you through the creation of an ubuntu linux virtual server with apache web server  mysql database and php scripting  
GPXX03HFEN,fundamentals of javascript through rock paper scissors,in this hands on project you will be recreating the game of rock  paper  scissors using the versatile and popular programming language  javascript 
RP0103,using r with databases,the intent of this course is to teach you how to unlock the power and magic of r to analyze data in relational databases  it will show you how to connect to relational databases  access and query the database  update and modify the data  analyze it and perform simple visualizations 
RP0103EN,using r with databases,using r with databases teaches you how to access and perform data analysis using r when your data is stored in a relational database mangement system  rdbms   in the course we will focus on using rodbc as our interface and we will use db2 express c and blu acceleration for cloud as our database server environment 
BD0212EN,spark fundamentals ii,building on your foundational knowledge of spark  take this opportunity to move your skills to the next level  with a focus on spark resilient distributed data set operations this course exposes you to concepts that are critical to your success in this field 
GPXX0IBEN,data science in insurance  basic statistical analysis ,in this guided project you will learn how to calculate basic descriptive statistics using apache spark 
SECM03EN,apply end to end security to a cloud application,this mini course walks you through key security services available in the ibm cloud‚ñ¢ catalog and how to use them together  an application that provides file sharing will put security concepts into practice 
SC0103EN,spark overview for scala analytics,"the ‚  spark overview for scala analytics‚äù course will cover the history of spark and how it came to be  how to build applications with spark  establish an understanding of rdds and dataframes  and other advanced spark topics  apache spark‚ñ¢ is a fast and general engine for large scale data processing  with built in modules for streaming  sql  machine learning and graph processing  having finished this class  a student would be prepared to leverage the core rdd and dataframe apis to perform analytics on datasets 
this course is meant to be an overview of spark and its associated ecosystem   for deeper understanding of spark  we recommend that students take the spark fundamentals courses i and ii "
GPXX0YXHEN,testing a microprofile or jakarta ee application using microshed testing with an open liberty docker container,learn how to use microshed testing to test a microprofile or jakarta ee application 
RP0151EN,r 101,in this introduction to r  you will master the basics of this beautiful open source language  including factors  lists and data frames  with the knowledge gained in this course  you will be ready to undertake your first very own data analysis  with over 2 million users worldwide r is rapidly becoming the leading programming language in statistics and data science  every year  the number of r users grows by 40  and an increasing number of organizations are using it in their day to day activities  leverage the power of r by completing this free r online course today 
TA0105,text analytics 101,analyze text data using analytics and machine learning models
SW0201EN,how to build watson ai and swift apis and make money,expose your cool swift microservices to the world and build a platform to monetize those apis  by using server side swift and your mobile apps  you ll also learn to be a better full stack developer  
TMP0106,data science bootcamp,a multi day intensive  in person data science bootcamp offered by big data university
GPXX0BUBEN,insurance risk assessment with montecarlo method using apache spark ,learn about the monte carlo method and calculate the ruin probability of an insurance company using apache spark 
ST0201EN,statistics 201,statistics courses teaching basic statistical anlysis methods
ST0301EN,statistics 301,statistics courses teaching advanced statistical anlysis methods
SW0101EN,build swift mobile apps with watson ai services,build three ai ios apps in the cloud by using watson services so that you can analyze the emotion and sentiment in text  recognize what s in a photo  and convert text to speech 
TMP0101EN,text analysis,analyze text data using various analytics and machine learning models
DW0101EN,introduction to machine learning with sound,get hands on experience creating and training machine learning models so that you can predict what animal is making a specific sound  like a cat purring or a dog barking  integrate those models in a simple web page that you build in node red  then  add visual recognition so that you can identify the image of an animal   
BD0143EN,using hbase for real time access to your big data,this course introduces you to hbase  the open source hadoop database used for random  real time read writes to your big data  the course will cover fundamental concepts of hbase such as hbase system and architecture  the use of the client api to perform data operations on hbase  the various hbase client used to communicate with hbase  how to integrate hbase with a mapreduce job  and more 
WA0101EN,watson analytics 101,welcome to watson analytics 101 
GPXX04HEEN,insurance business modelling and basic actuarial calculations,in this guided project you will learn how to build a mathematical model of an insurance company using risk process and to do risk and revenue assessment 
BD0141EN,accessing hadoop data using hive,hive is a data warehousing tool built on top of hadoop  learn how to easily query and analyze your big data projects with this free apache hive course 
CO0401EN,beyond the basics  istio and ibm cloud kubernetes service,start managing your microservices with istio on ibm cloud kubernetes service  this course shows you how to better  control traffic to services  observe service health  and secure the service mesh 
ML0122ENv1,accelerating deep learning with gpu,majority of data in the world are unlabeled and unstructured data  for instance images  sound  and text data  shallow neural networks cannot easily capture relevant structure in these kind of data  but deep networks are capable of discovering hidden structures within¬†these data  in this course  you will use tensorflow library to apply deep learning on different data types to solve real world problems 
BD0151EN,text analytics 101,the analysis of emails  blogs  tweets  forums and other forms of unstructured text data constitutes what we call text analytics   text analytics is applicable to most industries  for example  if your company is suspicious about company secrets being leaked to competitors by employees  text analytics can help analyze millions of employees   emails   if you would like to find common pain points your customers face when using your products  you can analyze their comments and questions in forums  if you would like to measure positive or negative perceptions of a company  brand  or product  you can perform sentiment analysis using text analytics  this course teaches you the basics of text analytics 
TA0106EN,text analytics at scale,a continuation of text analytics getting results with systemt  this course shows how early information extraction systems based on a standard formalism of cascading grammars suffer from fundamental limitations in both expressivity and runtime performance  the class explains in detail how these limitations are addressed via the declarative principles in the systemt information extraction system  resulting in extractors that are scalable  accurate and easy to maintain and enhance for a new domain 
TMP107,data science bootcamp with python,data science bootcamp with python
ML0111EN,machine learning with apache systemml,apache systemml is a declarative style language designed for large scale machine learning  it provides automatic generation of optimized runtime plans ranging from single node  to in memory  to distributed computations on apache hadoop and apache spark  systemml algorithms are expressed in r like or python like syntax that includes linear algebra primitives  statistical functions and ml specific constructs  
GPXX048OEN,action classification task based on internet firewall logs,learn how to build a mathematical model of an insurance company using risk process and to do risk and revenue assessment  
CO0201EN,container   kubernetes essentials with ibm cloud,get hands on experience with kubernetes container orchestration  learn how kubernetes and ibm cloud kubernetes service help you more easily deploy and scale containers and applications 
GPXX01DCEN,data science in health care  advanced prognostication using neural networks,learn to predict the covid 19 spread dynamics in the world using neural networks of different structures  
GPXX04XJEN,advanced machine   deep learning for spam classification task,learn to build the machine   deep learning models at the junction of nlp and network security areas by the help of sms spam collection dataset with the helping frameworks   libraries 
GPXX0JZ4EN,visual data analysis in banking,learn to master the visual data analysis in banking for machine learning models  
GPXX0ZYVEN,secure analysis of credit card dataset,learn to make the preliminary data analysis in security area based on credit clients card dataset with the helping frameworks and libraries 
GPXX0ZMZEN,data science in health care  advanced machine learning classification,learn to apply an advanced analysis of big data to the spread of covid 19 in the world  
GPXX0742EN,network traffic anomaly detection  intrusion detection task ,learn to build the model at the junction of nlp and network security areas with the help of intrusion detection evaluation dataset  iscxids2012  and the helping frameworks   libraries 
GPXX0KV4EN,getting started with node js,have you heard of node js before  node js is one of the most popular technology to create server side apps  why  because if you know javascript  you build both the frontend and the backend using javascript  take this guided project to get started on node js 
GPXX01RYEN,getting started with mysql command line,in this project  you will use the mysql command line interface  cli  to create a database and to restore the structure and contents of tables  then you will learn how to explore and query tables  finally  you will learn how to dump backup tables from database 
CC0120EN,an introduction to ibm cloud satellite,"a short introduction to ibm cloud satellite  learn why clients are so excited to implement the features and functionality ibm cloud satellite provides 
"
QC0101EN,introduction to quantum computing,this course introduces you to the strange world of quantum computing 
GPXX0YMEEN,launch an ai hotdog detector as a serverless python app,have you ever wondered if a picture has a hotdog in it or not  well  no longer do you have to wonder‚ you can now prove it  with this fun project  you‚ will learn how to create and launch a web app in python that tells you just that  whether or not a picture has a hotdog in it  let  s settle the great debate once and for all  learning skills that can help you land your next big job or pursue your million dollar idea while you  re at it 
GPXX0Q8AEN,exploratory data analysis  eda  with pandas in banking,learn to master the exploratory data analysis  eda  in banking with pandas framework 
TA0105EN,text analytics 101,from social media to news articles to machine logs  text data is everywhere  are you interested in learning how to derive valuable insights from text data  enroll today and learn about the hot topic of text analytics from experts at ibm 
GPXX0XFQEN,create tables and load data in mysql using phpmyadmin,in this project  you will learn how to create tables and load data in the mysql database service using the phpmyadmin graphical user interface  gui  tool 
GPXX07REN,relational model concepts,in this project  you will learn the concepts of a relational model including the terms entity  attribute  relation  degree  and cardinality  then apply the concepts you have learned to a real world example of a database 
PA0101EN,predictive modeling fundamentals i,the predictive modelling fundamentals i course where students can take this course many times as they wish and is totally free  after the students completed the course  they will be to print their online certificate of achievement    labs are available for download only for free trial of ibm spss modeler 
BC0202EN,build an iot blockchain network for a supply chain,learn how to use a an iot asset tracking device  build a blockchain network  and configure a node red dashboard to monitor a perishable network supply chain  you can also use a simulated tracker if you don t want to purchase and set up the hardware 
BC0101EN,blockchain essentials,understand blockchain technology and how it can solve business problems  learn the basics of developing applications with chaincode 
GPXX0725EN,getting started with postgresql command line,in this project  you will use the postgresql command line interface  cli  to a create database and to restore the structure and contents of tables  then you will learn how to explore and query tables  finally  you will learn how to dump backup tables from a database 
BC0201EN,ibm blockchain foundation developer,dive deeper into blockchain business networks and their components  ledgers  consensus  smart contracts  and more  learn how to build your first blockchain application and get more experience with hyperledger composer and chaincode to build networks  
GPXX0MIIEN,keys and constraints in mysql,in this project  you will learn how to add keys to create relationships between the tables and how to use constraints to enforce rules on the data entry in the mysql database service using the phpmyadmin graphical user interface  gui  tool 
BD0223EN,exploring spark s graphx,spark provides a graph parallel computation library in graphx  graph parallel is a paradigm that allows representation of your data as vertices and edges  spark s graphx provides a set of fundamental operators in addition to a growing collection of algorithms and builders to simplify graph analytics tasks 
GPXX0435EN,data science in health care  basic statistical analysis ,in this guided project you will learn how to download  pre preparate and make statistical analysis of elisa tests and collected information about igg and igm  vaccination influenza  vaccination tuberculosis and previous diseases and blood groups 
GPXX06ZLEN,create tables and load data in postgresql using pgadmin,in this project  you will learn how to create tables and load data in the postgresql database service using the pgadmin graphical user interface  gui  tool 
GPXX0QS6EN,monitoring the metrics of java microservices using eclipse microprofile metrics,you will explore how to provide system and application metrics from a microservice with microprofile metrics 
GPXX07YGEN,configuring microservices running in kubernetes,explore how to externalize configuration using microprofile config and configure your microservices using kubernetes configmaps and secrets 
AI0111EN,game playing ai with swift for tensorflow  s4tf ,in this course  you re going to learn how to accelerate machine learning model development with google s new swift for tensorflow framework  by building ai agents to play games like tic tac toe  cartpole  and 2048 
GPXX0QJFEN,enabling cross origin resource sharing  cors  in a restful java microservice,learn how to enable cross origin resource sharing  cors  in open liberty without writing java code 
GPXX0LLEEN,getting started with db2 on cloud,in this project  you will learn how to create tables and load data in ibm db2 
BD0121EN,apache pig 101,pig was initially developed at yahoo  to allow people using hadoop to focus more on analyzing large data sets and spend less time having to write mapper and reducer programs  like actual pigs  who eat almost anything  the pig programming language is designed to handle any kind of data‚ hence the name 
BD0135EN,developing distributed applications using zookeeper,in this course  you will explore the zookeeper framework in tandem with ibm biginsights modules and java to learn how to develop and manage distributed applications in the domain of big data  real world examples will be used to contextualize and motivate further study 
BD0133EN,controlling hadoop jobs using oozie,this apache oozie course teaches you how to control hadoop jobs on your big data projects  even better  the materials and software provided are all free 
BD0131EN,moving data into hadoop,this course describes techniques for moving data into hadoop  there are a variety of ways to get data into hadoop from simple hadoop shell commands to more sophisticated processes  several techniques are presented but three  sqoop  flume  and data click are covered in greater detail 
BD0115EN,mapreduce and yarn,string together your understanding of yet another resource negotiator  yarn  by gaining exposure to mapreduce1  the tool sets that start the processing of big data 
GPXX04V3EN,deploy a web server using python and ibm cloud engine,deploy a web server using python and ibm cloud engine
GPXX05P1EN,acknowledging messages using microprofile reactive messaging,learn how to acknowledge messages by using microprofile reactive messaging 
GPXX0D14EN,build a personal movie recommender with django,"choosing a good movie to watch on a weekend evening is always hard   it would be great if there is a 
handy movie recommender to help you make a good decision "
GPXX0G3KEN,managing and injecting dependencies into java microservices using contexts and dependency injection  cdi ,"learn how to use contexts and dependency injection  cdi  to manage scopes and inject dependencies into microservices 

"
BD0211EN,spark fundamentals i,ignite your interest in spark with an introduction to the core concepts that make this general processor an essential tool set for working with big data 
GPXX0HZ2EN,deploying microservices to kubernetes,deploy microservices in open liberty docker containers to kubernetes and manage them with the kubernetes cli  kubectl 
GPXX04TNEN,getting started with open liberty,learn how to develop a java application on open liberty with maven and docker 
GPXX0IHMEN,consuming restful java microservices asynchronously using eclipse microprofile rest client,learn how to use microprofile rest client to invoke restful microservices asynchronously over http 
ST0101EN,statistics 101,take this course and you won t fail statistics  welcome to the statistics 101 course  taught by murtaza haider  assistant professor at ryerson university  statistics is one of the most challenging topics to learn  but murtaza brings a gentle introduction to statistics in practice  learn about descriptive statistics  variance  probability  correlation  and data visualization  this course ends with a fully guided statistics exercise exploring the ‚  hot‚äù topic of  do good looking professors get better teaching evaluations  a free trial of spss statistics is included in this course     
BD0153EN,analyzing big data with a spreadsheet ui,this course is designed to introduce the student to the capabilities of bigsheets  bigsheets is a component of ibm biginsights  it provides the analyst the ability to be able to visualize and analyze data stored hdfs using a spreadsheet type interface without any programming 
DP0101EN,openrefine 101,"this introduction course is for a less technical user  business analyst or consultant interested to learn data science 


"
BD0137EN,solr 101,this course introduce you to solr
ML0120EN,deep learning with tensorflow,majority of data in the world are unlabeled and unstructured data  for instance images  sound  and text data  shallow neural networks cannot easily capture relevant structure in these kind of data  but deep networks are capable of discovering hidden structures within¬†these data  in this course  you will use tensorflow library to apply deep learning on different data types to solve real world problems 
GPXX0E3QEN,building fault tolerant microservices with the  fallback annotation,explore how to manage the impact of failures by using microprofile and istio fault tolerance to add retry and fallback behaviours to microservices 
GPXX0XV3EN,consuming restful java microservices with template interfaces using eclipse microprofile rest client,learn how to use microprofile rest client to invoke restful microservices over http in a type safe way 
CB0201EN,build chatbots with watson assistant,in this course  you ll explore the watson conversation service in depth  you ll watch videos that explain conversational concepts and apply them to build a chatbot  you will complete seven hands on labs  culminating in the creation of your own fully functional chatbot 
CB0105ENv1,node red  basics to bots,create cognitive web apps with node red to translate text  analyze tone  and send tweets  build a chatbot with watson assistant  formerly conversation  and facebook messenger 
GPXX0NHZEN,normalization   keys   constraints in relational database,in this project  you will learn about normalization  keys  and constraints in ibm db2 on cloud using sql  first  you will learn how to minimize data redundancy and inconsistency in a database by normalizing tables  next  you will learn how to use keys to uniquely identify a record in a table  to establish a relationship between tables  and to identify the relation between them  lastly  you will learn about different kinds of relational model constraints that help to maintain data integrity in a relational data model 
CL0101EN,ibm cloud essentials,the ibm cloud name has been changed to ibm cloud  get hands on experience with ibm cloud  cloud foundry  and best practices for agile and test driven development 
CO0301EN,getting started with microservices with istio and ibm cloud kubernetes service,discover how microservices and istio pair together for cloud native apps  learn how istio and ibm cloud kubernetes service help you securely and seamlessly deploy containers and apps 
GPXX0XENEN,playing tictactoe with reinforcement learning and openai gym,learn how to create and teach an agent that never loses to play tictactoe using a reinforcement learning algorithm called temporal difference learning and open ai gym
GPXX0HAAEN,deploying a microservice to openshift by using a kubernetes operator,explore how to deploy a microservice to red hat openshift by using a kubernetes operator 
DA0201EN,data analysis demos,this course is about providing demonstrations and showing results with the goal of inspiring you to take more technical and in depth courses
DJ0101EN,data journalism  first steps  skills and tools,this free data journalism course presents a holistic approach to data journalism  and answers fundamental questions about data journalism 
CP0101EN,mathematical optimization for business problems,mathematical optimization for business problems
DB0111EN,db2 academic training,db2 academic training
DB0115EN,db2 fundamentals ii,db2 fundamentals ii
COM001EN,scalable web applications on kubernetes,this mini course walks you through how to scaffold a web application  run it locally in a container  and then deploy it to a kubernetes cluster created with kubernetes service  additionally  you will learn how to bind a custom domain  monitor the health of the environment  and scale the application 
DA0151EN,data analysis using r 101,data analysis using r 101 teaches you how to perform data analysis using the r language  r is a powerful open source language that is ideal for analyzing both structured and unstructured data  in this course we will focus on performing analysis of unstructured data files 
DB0151EN,nosql and dbaas 101,in this nosql course  we will provide an overview of the nosql database landscape  the benefits of using a database as a service offering  and where cloudant fits into the picture  additionally  we‚ will get you started with using cloudant by providing tutorials on account sign up  creating and replicating databases  loading and querying data  and conclude by pointing you to additional resources to continue on your education 
CO0302EN,kubernetes operators advanced,this course covers advanced operator topics including reconciliation  use of operator lifecycle manager to deploy and upgrade operators  and use of scorecard to test operators 
GPXX0T0FEN,project  deploy a serverless app for image processing,in this project you will learn about serverless computing  will practice deploying a real application to a serverless environment based on ibm cloud code engine powered by kubernetes and knative open source projects  
DS0107,data science career talks,data science career talks
DS0110EN,data science with open data,data science with open data
DX0107EN,data science bootcamp with python for university professors,data science bootcamp with python for university professors
DS0321EN,bitcoin 101,greetings and welcome to the introduction to bitcoin course 
DS0105EN,data science hands on with open source tools,what tools do data scientists use  in this course  you ll learn how to use the most popular data science tools  including jupyter notebooks  rstudio ide  apache zeppelin  and more 
DS0103EN,data science methodology,grab you lab coat  beakers  and pocket calculator‚wait what  wrong path  fast forward and get in line with emerging data science methodologies that are in use and are making waves or rather predicting and determining which wave is coming and which one has just passed 
GPXX0I4FEN,creating asynchronous java microservices using microprofile reactive messaging,learn how to write reactive java microservices using microprofile reactive messaging 
GPXX06KEEN,build a smart search form with algolia,great search is an essential feature that all of the best applications share  in this project  we ll leverage the power of algolia to build our own smart search form from scratch 
GPXX0YBFEN,documenting restful apis using microprofile openapi,explore how to document and filter restful apis from code or static files by using microprofile openapi 
LB0109ENv1,reactive architecture  distributed messaging patterns,reactive architecture  distributed messaging patterns
GPXX0KHHEN,data science in agriculture  land use classification,in this lab  we will learn the basic methods of images transformation classification 
LB0111EN,reactive architecture  cqrs   event sourcing,reactive architecture  cqrs   event sourcing
ML0115EN,deep learning 101,deep learning 101
LB0105ENv1,reactive architecture  reactive microservices,when we use the term reactive  we are usually talking about reactive microservices  but what is a microservice  and how can we make it reactive  this course will explore the difference between monoliths and microservices and show the journey to making a system reactive 
LB0103ENv1,reactive architecture  domain driven design,domain driven design is a technique commonly used to build reactive systems  this course will introduce the core elements of domain driven design  it will also explain how those elements relate to reactive systems 
IT0101EN,building robots with tjbot,learn how to program a simple robot  tjbot  to move its arm  recognize objects  flash a light  speak  and more  you can build simple apps to control tjbot by using node js or even node red  if you don t want to purchase the tjbot  you use a simulator instead 
CC0250EN,building cloud native and multicloud applications,"this course introduces you to concepts related to migrating  modernizing  building and delivering applications in cloud native and multicloud environments   you will learn how to make informed decisions about application migration and enterprise modernization   

this course is of interest to anyone and everyone who wants to learn about cloud native and multicloud environments  it provides information to those who want to work on cloud native development projects  on legacy modernization projects  on devops engineering projects or as it cloud administrators "
BD0101EN,big data 101,how big is big and why does big matter and what does apache hadoop have to do with it  in this course you will see the big data big picture and you will learn the terminology used in big data discussions 
EE0101EN,modernizing java ee applications,learn about the techniques and tools available to take existing applications and update them to run on cloud native computing platforms  complete this course to level up in your understanding of modernization and migration options and earn an ibm badge 
GPXX04P5EN,data science in agriculture  prognostication using by neural network,in this lab  we will learn the basic methods of forecasting using linear regression and neural networks  
CO0101EN,docker essentials  a developer introduction,learn how to use containers for your applications  create and run your first docker container  then  learn how to run containers in production and solve problems of orchestration such as high availability  service discovery  and reconciliation 
ML0122ENv3,accelerating deep learning with gpus,training complex deep learning models with large datasets takes along time  in this course  you will learn how to use accelerated gpu hardware to overcome the scalability problem in deep learning 
LB0107ENv1,reactive architecture  building scalable systems,reactive architecture  building scalable systems
CB0101EN,build your own chatbots,learn how to build chatbots without having to write any code by leveraging watson assistant  then deploy your chatbot to a real site in less than five minutes 
GPXX0PG8EN,data science in agriculture  basic statistical analysis and geo visualisation,in this lab  we will learn how to download data  perform basic statistical analysis  visualize and display it on dynamic maps 
ML0101EN,machine learning with python,are the phrases ‚  it is certain    ‚  yes you may rely on it    ‚  reply hazy try again   common in your predictions  make room on your shelf for your magic eight ball and take this opportunity to see how machine learning can be a beneficial tool for predicting future trends  all with a bit more than oil and blue die  all signs point to yes as an indicator you will benefit from this experience 
CB0103EN,build your own chatbot,learn how to build chatbots without having to write any code by leveraging watson assistant  then deploy your chatbot to a real site in less than five minutes 
ML0109EN,machine learning   dimensionality reduction,machine learning   dimensionality reduction
ML0101ENv3,machine learning with python,machine learning can be an incredibly beneficial tool to uncover hidden insights and predict future trends  this free machine learning with python course will give you all the tools you need to get started with supervised and unsupervised learning 
GPXX0M7ZEN,consuming a restful java web service using json b and json p,explore how to access a simple restful web service and consume its resources in java using json b and json p 
CC0121EN,an introduction to ibm cloud for financial services,"learn about the target market segment for financial services  customer issues and challenges  and the benefits of ibm cloud for financial services  

"
DA0101EN,data analysis with python,in this course you will learn about  data acquisition how to obtain basic insight from a dataset data
GPXX07UGEN,testing reactive java microservices using microshed testing framework,learn how to test reactive java microservices in true to production environments using microshed testing 
GPXX0QU9EN,checking the health of java microservices by using kubernetes readiness and liveness probes,learn how to check the health of microservices on kubernetes by setting up readiness and liveness probes to inspect microprofile health check endpoints 
SC0101EN,scala 101,the typesafe scala 101 for data science curricula is designed to give experienced data developers and data science the know¬≠how to confidently start programming in scala for data science tasks  the course ensures they will have a solid understanding of the fundamentals of the language  the tooling and the development process as well as a good appreciation of the more advanced features  if students already have scala programming experience  then this course could be a useful refresher  yet no previous knowledge of scala is assumed 
GPXX0QTEEN,checking the health of java microservices by using eclipse microprofile health check,explore how to report and check the health of a microservice with microprofile health 
GPXX0WTIEN,train a hotdog image recognition model with python,we all know that machines can do a lot these days  including recognizing whether or not an image has a certain object in it  but did you know that you  too  can train a model to do just that  in this guided project  you‚ will learn how to train a model in python with pytorch  a machine learning library  to detect if a picture has a hotdog in it  this process can be repeated with any object  whether it is a bird  a plane or even superman 
GPXX08WYEN,externalizing configuration for java microservices using eclipse microprofile config,learn how to provide external configuration to microservices using microprofile config 
GPXX0UMSEN,integrating restful services with a reactive system,learn how to integrate restful java microservices with a reactive system by using microprofile reactive messaging 
GPXX0M6UEN,using the cql shell to execute keyspace operations in cassandra,in this guided project  you will use the cassandra query language command line shell and execute keyspace operations in a cassandra database 
GPXX097UEN,performing table and crud operations with cassandra,in this guided project  you will create a table and perform create  read  update  delete  crud  operations in cassandra using the cql shell  cqlsh  command line interface 
SN0111EN,how to create and publish guided projects and hands on labs,in this preview version of the course  only the lab instructions are available to get you started with creating hands on labs and guided projects  in the coming weeks  we will enhance the course with videos  assessments  and a course certificate 
GPXX0JGFEN,building a simple restful java microservice using jax rs and json b,learn how to create a rest service with jax rs  json b  and open liberty 
CO0193EN,hybrid cloud conference   backend services for containers,hybrid cloud conference   backend services for containers
GPXX0HC7EN,transform photos to sketches and paintings with opencv,have you wanted to transform your photographs in an artistic sketch or painting to showcase your creativity ¬† in this guided project you ll do just that  transform your photographs to paintings  sketches and more using opencv in python 
GPXX04MXEN,quick introduction to a b testing,experimental design refers to how users are allocated to the different groups in an experiment  a b testing is an experiment set up to compare two versions of something to decide which performs better 
DS0101EN,introduction to data science,the art of uncovering the insights and trends in data has been around since ancient times  the ancient egyptians used census data to increase efficiency in tax collection and they accurately predicted the flooding of the nile river every year  since then  people working in data science have carved out a unique and distinct field for the work they do  this field is data science  in this course  we will meet some data science practitioners and we will get an overview of what data science is today 
LB0101ENv1,reactive architecture  introduction to reactive systems,this course teaches the core principles behind reactive architecture  it introduces students to why we need reactive systems  and what problems they are trying to solve  it also contrasts reactive architectures with reactive programming  showing how they relate  and how they are different 
DS0301EN,data privacy fundamentals,data privacy fundamentals
GPXX0RL8EN,consuming a restful java web service with angularjs,explore how to access a simple restful web service and consume its resources with angularjs in open liberty 
GPXX05LMEN,implement consumer driven contract testing for java microservices using the pact framework,learn how to test java microservices with consumer driven contracts in open liberty 
BD0111EN,hadoop 101,this free apache hadoop course introduces you to big data concepts  and teaches you how to perform distributed processing of large data sets with hadoop 
CC0101EN,introduction to cloud,this course introduces you to the core concepts of cloud computing  you will gain the foundational knowledge required for understanding cloud computing from both business and practitioner perspectives 
GPXX0UN5EN,classification of yelp reviews using sentiment analysis,sentiment analysis has become a very popular tool to extract subjective information from the social media and to help businesses understand the social sentiment of their brand  product or service   in this guided project  you will be introduced to several natural language processing techniques to help you derive some meaning from yelp business reviews  as well as to build and test a classification model to divide these reviews into positive or negative 
BD0221EN,spark mllib,spark provides a machine learning library known as mllib  mllib provides various machine learning algorithms such as classification  regression  clustering  and collaborative filtering  it also provides tools such as featurization  pipelines  persistence  and utilities for handing linear algebra operations  statistics and data handling 
CC0103EN,ibm cloud essentials   v3,this course introduces you to the ibm cloud  you will learn about the many offerings and services on ibm cloud that make it the most open and secure public cloud for developers and enterprises 
GPXX0TY1EN,performing database operations in the cloudant dashboard,in this guided project  you will launch ibm cloudant to explore database as a service  dbaas  operations  perform simple operations like querying or copying data  and monitor activities on the dashboard 
GPXX0T3CEN,working with databases in ibm cloudant,in this guided project  you will explore database operations in ibm cloud by working with real estate data 
PY0101EN,python for data science,this beginner friendly python course will take you from zero to programming in python in a matter of hours  you ll be able to write your own python scripts and perform basic hands on data analysis using our jupyter based lab environment 
CC0201EN,introduction to containers  kubernetes  and openshift v2,this course introduces the core concepts of containers and kubernetes and explains how containers differ from virtual machines  it also covers the importance of containers in cloud computing as well as the emerging ecosystem of related technologies such as docker  kubernetes  openshift  istio and knative 
BD0123EN,simplifying data pipelines with apache kafka,when you hear the terms  producer  consumer  topic category  broker  and cluster used together to describe a messaging system  something is brewing in the pipelines  get connected and learn what that is  and what it means 
DB0101EN,sql and relational databases 101,are you ready to dive into the world of sql and relational databases  in just a few hours  you ll be able to discuss sql basics and explain various aspects of the relational database model  try our hands on exercises as we guide your first steps into sql and relational databases 
GPXX05RDEN,medical appointment data analysis,in this notebook we will try to analyze why would some patients not show up for their medical appointment and whether there are reasons for that using the data we have 
DV0151EN,data visualization with r,data visualization is the presentation of data with graphics  it s a way to summarize your findings and display it in a form that facilitates interpretation and can help in identifying patterns or trends  in this course you will learn how to create beautiful graphics and charts  customizing the look and feel of them as you wish 
GPXX0BSAEN,implementing a graphql microservice using microprofile api to query and update data from multiple services,learn how to use microprofile graphql to query and update data from multiple services  and how to test graphql queries and mutations using an interactive graphql tool  graphiql  
GPXX0G81EN,consuming a restful java web service with reactjs,explore how to access a simple restful web service and consume its resources with reactjs in open liberty 
GPXX0FFCEN,building and testing a java web application with maven and open liberty,learn how to build and test a simple web application using maven and open liberty 
GPXX0MP0EN,building a hypermedia driven restful java microservice using hypermedia as the engine of application state  hateoas ,you‚ will explore how to use hypermedia as the engine of application state  hateoas  to drive your restful web service on open liberty 
DV0101EN,data visualization with python,data visualization is the graphical representation of data in order to interactively and efficiently convey insights to clients  customers  and stakeholders in general  it is a way to summarize your findings and display it in a form that facilitates interpretation and can help in identifying patterns or trends  in this data visualization with python course  you ll learn how to create interesting graphics and charts and customize them to make them more effective and more pleasing to your audience 
ML0103EN,digital analytics   regression,this course uses a case study approach to take you through the end to end process of identifying a business objective  designing the model to address it  sourcing the data and ultimately arriving at the insights  when you complete this course  you can apply these methods and principles in a variety of contexts  with big  medium or small data 
ML0151EN,machine learning with r,this machine learning with r course dives into the basics of machine learning using an approachable  and well known  programming language  you ll learn about supervised vs unsupervised learning  look into how statistical modeling relates to machine learning  and do a comparison of each 
GPXX01AVEN,containerizing and running java microservices in docker containers,learn how to containerize and run your microservices with open liberty using docker 
ML0120ENv2,deep learning with tensorflow,majority of data in the world are unlabeled and unstructured data  for instance images  sound  and text data  shallow neural networks cannot easily capture relevant structure in these kind of data  but deep networks are capable of discovering hidden structures within¬†these data  in this course  you will use tensorflow library to apply deep learning on different data types to solve real world problems 
RP0101EN,r for data science,are you ready to dive head first into r  in just a few hours you ll learn how to write your own r code  learn about data structures and create your own functions  you‚ will even be able to import data and do some operations  try our hands on exercises as we guide your first steps into your data science journey with r 
GPXX0G31EN,accessing and persisting data in microservices using java persistence api  jpa ,learn how to use java persistence api  jpa  to access and persist data to a database for your microservices 
GPXX0KY1EN,data science in health care  basic prognostication and geo visualization,in this guided project we will study how make predictions based on linear regression  obtain statistics and create interactive maps showing the dynamics of virus spread 
GPXX0JLHEN,enabling distributed tracing in java microservices using eclipse microprofile opentracing and the jaeger tracing system ,explore how to enable and customize tracing of jax rs and non jax rs methods by using microprofile opentracing and jaeger 
CC0150EN,building cloud native and multicloud applications,in this course  we will cover the core concepts and practices of building and running cloud native applications and how to run these applications in a multicloud environment  we will cover technologies and practices including  microservices  devops  ci cd  docker  kubernetes  and openshift 
GPXX0QQ3EN,deploy an ai powered discord bot with a voice,discord is a fantastic way to connect with your friends or host a community and a bot is a perfect way to add features to your server  not only will this guided project show you how to get started in creating a bot  but you ll also learn how to power it with an ai chatbot and give it a voice  finally  you ll host it somewhere so that the bot is online without your computer being on  all of this for free 
GPXX0RQLEN,views in postgresql,in this project  you will learn how to create and execute views and materialized views in the postgresql database service using the pgadmin graphical user interface  gui  tool  materialized views behave differently compared to regular views  in materialized views  result set is materialized or saved for future use  you can t insert  update  or delete rows like in regular views  materialized views can improve performance 
GPXX0WRDEN,streaming updates from a microprofile reactive messaging microservice using server sent events  sse ,learn how to stream updates from a microprofile reactive messaging service to a front end client by using server sent events  sse  
GPXX0ADEN,consuming a restful java web service with angular,explore how to access a simple restful web service and consume its resources with angular in open liberty 
ML0120ENv3,deep learning with tensorflow,majority of data in the world are unlabeled and unstructured data  for instance images  sound  and text data  shallow neural networks cannot easily capture relevant structure in these kind of data  but deep networks are capable of discovering hidden structures within¬†these data  in this course  you will use tensorflow library to apply deep learning on different data types to solve real world problems 
SC0105EN,data science with scala,apache spark is a fast and general engine for large scale data processing  with built in modules for streaming  sql  machine learning and graph processing  this course shows how to use spark  s machine learning pipelines to fit models and search for optimal hyperparameters using a spark cluster 
excourse01,relational database systems,welcome to the specialization course relational database systems  this course will be completed on six weeks  it will be supported with videos and various documents that will allow you to learn in a very simple way how several types of information systems and databases are available to solve different problems and needs of the companies  objective  a learner will be able to design  test  and implement analytical  transactional or nosql database systems according to business requirements by programming reliable  scalable and maintainable applications and resources using sql and hadoop ecosystem  programming languages  for course 1 you will use the mysql language  software to download  mysql workbench in case you have a mac   ios operating system you will need to use a virtual machine  virtualbox  vmware  
excourse02,business intelligence and data warehousing,welcome to the specialization course business intelligence and data warehousing  this course will be completed on six weeks  it will be supported with videos and various documents that will allow you to learn in a very simple way how to identify  design and develop analytical information systems  such as business intelligence with a descriptive analysis on data warehouses  you will be able to understand the problem of integration and predictive analysis of high volume of unstructured data  big data  with data mining and the hadoop framework 
excourse03,nosql systems,"welcome to the specialization course of nosql systems  

this course will be completed on six weeks  it will be supported with videos and exercises that will allow you to identify the differences between the relational and nosql databases  
as part of these alternative technologies the student will learn the main characteristics and how to implement the typical nosql databases  such as key value  columnar  document and graph  
let s start 

after completing this course  a learner will be able to
identify what type of nosql database to implement based on business requirements  key value  document  full text  graph  etc  
apply nosql data modeling from application specific queries
use atomic aggregates and denormalization as data modelling techniques to optimize query processing

software to download 
mongodb
neo4j
sapiq
cassandra"
excourse04,"
sql for data science","as data collection has increased exponentially  so has the need for people skilled at using and interacting with data  to be able to think critically  and provide insights to make better decisions and optimize their businesses  this is a data scientist    part mathematician  part computer scientist  and part trend spotter    sas institute  inc    according to glassdoor  being a data scientist is the best job in america  with a median base salary of  110 000 and thousands of job openings at a time  the skills necessary to be a good data scientist include being able to retrieve and work with data  and to do that you need to be well versed in sql  the standard language for communicating with database systems 

this course is designed to give you a primer in the fundamentals of sql and working with data so that you can begin analyzing it for data science purposes  you will begin to ask the right questions and come up with good answers to deliver valuable insights for your organization  this course starts with the basics and assumes you do not have any knowledge or skills in sql  it will build on that foundation and gradually have you write both simple and complex queries to help you select data from tables   you ll start to work with different types of data like strings and numbers and discuss methods to filter and pare down your results  

you will create new tables and be able to move data into them  you will learn common operators and how to combine the data  you will use case statements and concepts like data governance and profiling  you will discuss topics on data  and practice using real world programming assignments  you will interpret the structure  meaning  and relationships in source data and use sql as a professional to shape your data for targeted analysis purposes  

although we do not have any specific prerequisites or software requirements to take this course  a simple text editor is recommended for the final project  so what are you waiting for  this is your first step in landing a job in the best occupation in the us and soon the world "
excourse05,"
distributed computing with spark sql","this course is all about big data  it  s for students with sql experience that want to take the next step on their data journey by learning distributed computing using apache spark  students will gain a thorough understanding of this open source standard for working with large datasets  students will gain an understanding of the fundamentals of data analysis using sql on spark  setting the foundation for how to combine data with advanced analytics at scale and in production environments  the four modules build on one another and by the end of the course you will understand  the spark architecture  queries within spark  common ways to optimize spark sql  and how to build reliable data pipelines  

the first module introduces spark and the databricks environment including how spark distributes computation and spark sql  module 2 covers the core concepts of spark such as storage vs  compute  caching  partitions  and troubleshooting performance issues via the spark ui  it also covers new features in apache spark 3 x such as adaptive query execution  the third module focuses on engineering data pipelines including connecting to databases  schemas and data types  file formats  and writing reliable data  the final module covers data lakes  data warehouses  and lakehouses  students build production grade data pipelines by combining spark with the open source project delta lake  by the end of this course  students will hone their sql and distributed computing skills to become more adept at advanced analysis and to set the stage for transitioning to more advanced analytics as data scientists "
excourse06,"
sql for data science capstone project","data science is a dynamic and growing career field that demands knowledge and skills based in sql to be successful  this course is designed to provide you with a solid foundation in applying sql skills to analyze data and solve real business problems 

whether you have successfully completed the other courses in the learn sql basics for data science specialization or are taking just this course  this project is your chance to apply the knowledge and skills you have acquired to practice important sql  querying and solve problems with data  you will participate in your own personal or professional journey to create a portfolio worthy piece from start to finish  you will choose a dataset and develop a project proposal  you will explore your data and perform some initial statistics you have learned through this specialization  you will uncover analytics for qualitative data and consider new metrics that make sense from the patterns that surface in your analysis  you will put all of your work together in the form of a presentation where you will tell the story of your findings  along the way  you will receive feedback through the peer review process  this community of fellow learners will provide additional input to help you refine your approach to data analysis with sql and present your findings to clients and management "
excourse07,database management essentials,database management essentials provides the foundation you need for a career in database development  data warehousing  or business intelligence  as well as for the entire data warehousing for business intelligence specialization  in this course  you will create relational databases  write sql statements to extract information to satisfy business reporting requests  create entity relationship diagrams  erds  to design databases  and analyze table designs for excessive redundancy  as you develop these skills  you will use either oracle  mysql  or postgresql to execute sql statements and a database diagramming tool such as the er assistant or visual paradigm to create erds  we  ve designed this course to ensure a common foundation for specialization learners  everyone taking the course can jump right in with writing sql statements in oracle  mysql  or postgresql 
excourse08,using databases with python,"this course will introduce students to the basics of the structured query language  sql  as well as basic database design for storing data as part of a multi step data gathering  analysis  and processing effort   the course will use sqlite3 as its database   we will also build web crawlers and multi step data gathering and visualization processes   we will use the d3 js library to do basic data visualization   this course will cover chapters 14 15 of the book   python for everybody    to succeed in this course  you should be familiar with the material covered in chapters 1 13 of the textbook and the first three courses in this specialization  this course covers python 3 
"
excourse09,process data from dirty to clean,"in this course  you  ll continue to build your understanding of data analytics and the concepts and tools that data analysts use in their work  you  ll learn how to check and clean your data using spreadsheets and sql as well as how to verify and report your data cleaning results  current google data analysts will continue to instruct and provide you with hands on ways to accomplish common data analyst tasks with the best tools and resources 

learners who complete this certificate program will be equipped to apply for introductory level jobs as data analysts  no previous experience is necessary 

by the end of this course  you will be able to do the following 
   learn how to check for data integrity 
   discover data cleaning techniques using spreadsheets  
   develop basic sql queries for use on databases 
   apply basic sql functions for cleaning and transforming data 
   gain an understanding of how to verify the results of cleaning data 
   explore the elements and importance of data cleaning reports "
excourse10,database architecture  scale  and nosql with elasticsearch,"you will explore database architecture  postgresql  and various scalable deployment configurations  you will see how postgresql implements basic crud operations and indexes  and review how transactions and the acid  atomicity  consistency  isolation  durability  requirements are implemented  

you  ll learn to use elasticsearch nosql  which is a common nosql database and a supplement to a relational database to high speed search and indexing  we will examine elasticsearch as an example of a base style  basic availability  soft state  eventual consistency  database approach  as well as compare and contrast the advantages and challenges associated with acid and base databases "
excourse11,the nature of data and relational database design,"this course provides a comprehensive overview of data  various data types  design of databases for storage of data  and creation and manipulation of data in databases using sql  by the end of this course  students will be able to describe what business intelligence is and how it  s different from business analytics and data science  conduct a basic descriptive statistical analysis and articulate the findings  and differentiate between types of statistics  they will also be able to define normalization and etl  create an erd that shows progression from conceptual to logical to physical design  define ddl  dml  dcl  and tcl  and write sql scripts to create a database and associated tables 
"
excourse12,python scripting  files  inheritance  and databases,"this course is the third course in a series that aims to prepare you for a role working as a programmer  in this course  you will be introduced to the three main concepts in programming  files  inheritance and external libaries   labs will allow the students to apply the material in the lectures in simple computer programs designed to re enforce the material in the lesson 
"
excourse13,relational database support for data warehouses,"relational database support for data warehouses is the third course in the data warehousing for business intelligence specialization  in this course  you ll use analytical elements of sql for answering business intelligence questions  you ll learn features of relational database management systems for managing summary data commonly used in business intelligence reporting  because of the importance and difficulty of managing implementations of data warehouses  we ll also delve into storage architectures  scalable parallel processing  data governance  and big data impacts  in the assignments in this course  you can use either oracle or postgresql 
"
excourse14,introduction to structured query language  sql ,"in this course  you ll walk through installation steps for installing a text editor  installing mamp or xampp  or equivalent  and creating a mysql database  you ll learn about single table queries and the basic syntax of the sql language  as well as database design with multiple tables  foreign keys  and the join operation  lastly  you ll learn to model many to many relationships like those needed to represent users  roles  and courses 
"
excourse15,crash course on python,"this course is designed to teach you the foundations in order to write simple programs in python using the most common structures  no previous exposure to programming is needed  by the end of this course  you ll understand the benefits of programming in it roles  be able to write simple programs using python  figure out how the building blocks of programming fit together  and combine all of this knowledge to solve a complex programming problem  

we ll start off by diving into the basics of writing a computer program  along the way  you  ll get hands on experience with programming concepts through interactive exercises and real world examples  you  ll quickly start to see how computers can perform a multitude of tasks    you just have to write code that tells them what to do "
excourse16,programming for everybody  getting started with python ,"this course aims to teach everyone the basics of programming computers using python  we cover the basics of how one constructs a program from a series of simple instructions in python   the course has no pre requisites and avoids all but the simplest mathematics  anyone with moderate computer experience should be able to master the materials in this course  this course will cover chapters 1 5 of the textbook   python for everybody     once a student completes this course  they will be ready to take more advanced programming courses  this course covers python 3 
"
excourse17,python basics,"this course introduces the basics of python 3  including conditional execution and iteration as control structures  and strings and lists as data structures  you ll program an on screen turtle to draw pretty pictures  you ll also learn to draw reference diagrams as a way to reason about program executions  which will help to build up your debugging skills  the course has no prerequisites  it will cover chapters 1 9 of the textbook   fundamentals of python programming    which is the accompanying text  optional and free  for this course 

the course is for you if you re a newcomer to python programming  if you need a refresher on python basics  or if you may have had some exposure to python programming but want a more in depth exposition and vocabulary for describing and reasoning about programs "
excourse18,python programming  a concise introduction,"the goal of the course is to introduce students to python version 3 x programming using hands on instruction  it will show how to install python and use the spyder ide  integrated development environment  for writing and debugging programs  the approach will be to present an example followed by a small exercise where the learner tries something similar to solidify a concept   at the end of each module there will be an exercise where the student is required to write simple programs and submit them for grading   it is intended for students with little or no programming background  although students with such a background should be able to move forward at their preferred pace 

the course is four modules long and is designed to be completed in four weeks "
excourse19,introduction to python programming,"this course provides an introduction to programming and the python language   students are introduced to core programming concepts like data structures  conditionals  loops  variables  and functions   this course includes an overview of the various tools available for writing and running python  and gets students coding quickly   it also provides hands on coding exercises using commonly used data structures  writing custom functions  and reading and writing to files  this course may be more robust than some other introductory python courses  as it delves deeper into certain essential programming topics 
"
excourse20,python and statistics for financial analysis,"python is now becoming the number 1 programming language for data science  due to python  s simplicity and high readability  it is gaining its importance in the financial industry   the course combines both python coding and statistical concepts and applies into analyzing financial data  such as stock data 

by the end of the course  you can achieve the following using python 

  import  pre process  save and visualize financial data into pandas dataframe

  manipulate the existing financial data by generating new variables using multiple columns

  recall and apply the important statistical concepts  random variable  frequency  distribution  population and sample  confidence interval  linear regression  etc    into financial contexts

  build a trading model using multiple linear regression model 

  evaluate the performance of the trading model using different investment indicators

jupyter notebook environment is configured in the course platform for practicing python coding without installing any client applications 
"
excourse21,applied machine learning in python,"this course will introduce the learner to applied machine learning  focusing more on the techniques and methods than on the statistics behind these methods  the course will start with a discussion of how machine learning is different than descriptive statistics  and introduce the scikit learn toolkit through a tutorial  the issue of dimensionality of data will be discussed  and the task of clustering data  as well as evaluating those clusters  will be tackled  supervised approaches for creating predictive models will be described  and learners will be able to apply the scikit learn predictive modelling methods while understanding process issues related to data generalizability  e g  cross validation  overfitting   the course will end with a look at more advanced techniques  such as building ensembles  and practical limitations of predictive models  by the end of this course  students will be able to identify the difference between a supervised  classification  and unsupervised  clustering  technique  identify which technique they need to apply for a particular dataset and need  engineer features to meet that need  and write python code to carry out an analysis  

this course should be taken after introduction to data science in python and applied plotting  charting   data representation in python and before applied text mining in python and applied social analysis in python "
excourse22,introduction to data science in python,"this course will introduce the learner to the basics of the python programming environment  including fundamental python programming techniques such as lambdas  reading and manipulating csv files  and the numpy library  the course will introduce data manipulation and cleaning techniques using the popular python pandas data science library and introduce the abstraction of the series and dataframe as the central data structures for data analysis  along with tutorials on how to use functions such as groupby  merge  and pivot tables effectively  by the end of this course  students will be able to take tabular data  clean it  manipulate it  and run basic inferential statistical analyses  

this course should be taken before any of the other applied data science with python courses  applied plotting  charting   data representation in python  applied machine learning in python  applied text mining in python  applied social network analysis in python "
excourse23,data analysis using python,"this course provides an introduction to basic data science techniques using python   students are introduced to core concepts like data frames and joining data  and learn how to use data analysis libraries like pandas  numpy  and matplotlib   this course provides an overview of loading  inspecting  and querying real world data  and how to answer basic questions about that data   students will gain skills in data aggregation and summarization  as well as basic data visualization 
"
excourse24,introduction to cloud computing,"this course introduces you to the core concepts of cloud computing  you gain the foundational knowledge required for understanding cloud computing from a business perspective as also for becoming a cloud practitioner  you understand the definition and essential characteristics of cloud computing  its history  the business case for cloud computing  and emerging technology usecases enabled by cloud  we introduce you to some of the prominent service providers of our times  e g  aws  google  ibm  microsoft  etc   the services they offer  and look at some case studies of cloud computing across industry verticals  

you learn about the various cloud service models  iaas  paas  saas  and deployment models  public  private  hybrid  and the key components of a cloud infrastructure  vms  networking  storage   file  block  object  cdn   we also cover emergent cloud trends and practices including   hybrid multicloud  microservices  serverless  devops  cloud native and application modernization  and we go over the basics of cloud security  monitoring  and different job roles in the cloud industry  

even though this course does not require any prior cloud computing or programming experience  by the end of the course  you will have created your own account on ibm cloud and gained some hands on experience by provisioning a cloud service and working with it 

this course is suitable for a large variety of audiences   whether you are an executive   manager   student who wants to become familiar with cloud computing terminology and concepts  or someone who wants foundational  grounding in cloud computing to start a career in this field or become a cloud practitioner   such as a cloud engineer  developer  analyst  etc 

the completion of this course also makes you eligible to earn the cloud computing core ibm digital badge   more information about the badge can be found here  https   www youracclaim com org ibm badge introduction to cloud computing"
excourse25,cloud computing basics  cloud 101 ,"welcome to cloud computing basics  cloud 101   

over the next few weeks  we will discuss the basics of cloud computing  what it is  what it supports  and how it is delivered  we will delve into storage services  cloud economics  levels of managed infrastructure  and azure services  we will also explore different deployment models of cloud computing  as well as several hosting scenarios  last but not least  we will compare some of the cloud platforms and discuss the future of cloud computing "
excourse26,cloud computing foundations,"welcome to the first course in the building cloud computing solutions at scale specialization  in this course  you will learn how to build foundational cloud computing infrastructure  including websites involving serverless technology and virtual machines  you will also learn how to apply agile software development techniques to projects which will be useful in building portfolio projects and global scale cloud infrastructures  

this course is ideal for beginners as well as intermediate students interested in applying cloud computing to data science  machine learning and data engineering  students should have beginner level linux and intermediate level python skills  for your project in this course  you will build a statically hosted website using the hugo framework  aws code pipelines  aws s3 and github "
excourse27,cloud computing concepts  part 1,"cloud computing systems today  whether open source or used inside companies  are built using a common set of core techniques  algorithms  and design philosophies    all centered around distributed systems  learn about such fundamental distributed computing   concepts   for cloud computing 

some of these concepts include  clouds  mapreduce  key value nosql stores  classical distributed algorithms  widely used distributed algorithms  scalability  trending areas  and much  much more  
 
know how these systems work from the inside out  get your hands dirty using these concepts with provided homework exercises  in the programming assignments  implement some of these concepts in template code  programs  provided in the c++ programming language  prior experience with c++ is required 
 
the course also features interviews with leading researchers and managers  from both industry and academia "
excourse28,fundamentals of cloud computing,"this course is the second of a series that aims to prepare you for a role working in data analytics  in this course  you will be introduced to many of the core concepts of cloud computing  you will learn about the primary deployment models  we  ll go through the common cloud computing service models  the hands on material offers the opportunity to review and configure a cloud account  this course covers a wide variety of topics that are critical for understanding cloud computing and are designed to give you an introduction and overview as you begin to build relevant knowledge and skills 
"
excourse29,cloud computing concepts  part 2,"cloud computing systems today  whether open source or used inside companies  are built using a common set of core techniques  algorithms  and design philosophies    all centered around distributed systems  learn about such fundamental distributed computing   concepts   for cloud computing 

some of these concepts include  clouds  mapreduce  key value nosql stores  classical distributed algorithms  widely used distributed algorithms  scalability  trending areas  and much  much more  
 
know how these systems work from the inside out  get your hands dirty using these concepts with provided homework exercises  in the programming assignments  implement some of these concepts in template code  programs  provided in the c++ programming language  prior experience with c++ is required 
 
the course also features interviews with leading researchers and managers  from both industry and academia "
excourse30,cloud computing applications  part 1  cloud systems and infrastructure,"welcome to the cloud computing applications course  the first part of a two course series designed to give you a comprehensive view on the world of cloud computing and big data  

in this first course we cover a multitude of technologies that comprise the modern concept of cloud computing  cloud computing is an information technology revolution that has just started to impact many enterprise computing systems in major ways  and it will change the face of computing in the years to come 

we start the first week by introducing some major concepts in cloud computing  the economics foundations of it and we introduce the concept of big data  we also cover the concept of software defined architectures  and how virtualization results in cloud infrastructure and how cloud service providers organize their offerings  in week two  we cover virtualization and containers with deeper focus  including lectures on docker  jvm and kubernates  we finish up week two by comparing the infrastructure as a service offering by the big three  amazon  google and microsoft  
week three moves to higher level of cloud offering  including platform as a service  mobile backend as a service and even serverless architectures  we also talk about some of the cloud middleware technologies that are fundamental to cloud based applications such as rpc and rest  json and load balancing  week three also covers metal as a service  maas   where physical machines are provisioned in a cloud environment  
week four introduces higher level cloud services with special focus on cloud storage services  we introduce hive  hdfs and ceph as pure big data storage and file systems  and move on to cloud object storage systems  virtual hard drives and virtual archival storage options  as discussion on dropbox cloud solution wraps up week 4 and the course "
excourse31,cloud computing applications  part 2  big data and applications in the cloud,"welcome to the cloud computing applications course  the second part of a two course series designed to give you a comprehensive view on the world of cloud computing and big data 

in this second course we continue cloud computing applications by exploring how the cloud opens up data analytics of huge volumes of data that are static or streamed at high velocity and represent an enormous variety of information  cloud applications and data analytics represent a disruptive change in the ways that society is informed by  and uses information  we start the first week by introducing some major systems for data analysis including spark and the major frameworks and distributions of analytics applications including hortonworks  cloudera  and mapr  by the middle of week one we introduce the hdfs distributed and robust file system that is used in many applications like hadoop and finish week one by exploring the powerful mapreduce programming model and how distributed operating systems like yarn and mesos support a flexible and scalable environment for big data analytics  in week two  our course introduces large scale data storage and the difficulties and problems of consensus in enormous stores that use quantities of processors  memories and disks  we discuss eventual consistency  acid  and base and the consensus algorithms used in data centers including paxos and zookeeper  our course presents distributed key value stores and in memory databases like redis used in data centers for performance  next we present nosql databases  we visit hbase  the scalable  low latency database that supports database operations in applications that use hadoop  then again we show how spark sql can program sql queries on huge data  we finish up week two with a presentation on distributed publish subscribe systems using kafka  a distributed log messaging system that is finding wide use in connecting big data and streaming applications together to form complex systems  week three moves to fast data real time streaming and introduces storm technology that is used widely in industries such as yahoo  we continue with spark streaming  lambda and kappa architectures  and a presentation of the streaming ecosystem  week four focuses on graph processing  machine learning  and deep learning  we introduce the ideas of graph processing and present pregel  giraph  and spark graphx  then we move to machine learning with examples from mahout and spark  kmeans  naive bayes  and fpm are given as examples  spark ml and mllib continue the theme of programmability and application construction  the last topic we cover in week four introduces deep learning technologies including theano  tensor flow  cntk  mxnet  and caffe on spark "
excourse32,introduction to data analytics,"this course presents a gentle introduction into the concepts of data analysis  the role of a data analyst  and the tools that are used to perform daily functions  you will gain an understanding of the data ecosystem and the fundamentals of data analysis  such as data gathering or data mining   you will then learn the soft skills that are required to effectively communicate your data to stakeholders  and how mastering these skills can give you the option to become a data driven decision maker 

this course will help you to differentiate between the roles of a data analyst  data scientist  and data engineer  you will learn the responsibilities of a data analyst and exactly what data analysis entails  you will be able to summarize the data ecosystem  such as databases and data warehouses  you will then uncover the major vendors within the data ecosystem and explore the various tools on premise and in the cloud  continue this exciting journey and discover big data platforms such as hadoop  hive  and spark  by the end of this course you will be able to visualize the daily life of a data analyst  understand the different career paths that are available for data analytics  and identify the many resources available for mastering this profession 

     throughout this course you will learn the key aspects to data analysis  you will begin to explore the fundamentals of gathering data  and learning how to identify your data sources  you will then learn how to clean  analyze  and share your data with the use of visualizations and dashboard tools  this all comes together in the final project where it will test your knowledge of the course material  explore what it means to be a data analyst  and provide a real world scenario of data analysis  "
excourse33,excel basics for data analysis,"this course is designed to provide you with basic working knowledge for using excel spreadsheets for data analysis  it covers some of the first steps for working with spreadsheets and their usage in the process of analyzing data   it includes plenty of videos  demos  and examples for you to learn  followed by step by step instructions for you to apply and practice on a live spreadsheet 

excel is an essential tool for working with data   whether for business  marketing  data analytics  or research  this course is suitable for those aspiring to take up data analysis or data science as a profession  as well as those who just want to use excel for data analysis in their own domains  you will gain valuable experience in cleansing and wrangling data using functions and then analyze your data using techniques like filtering  sorting and creating pivot tables    

this course starts with an introduction to spreadsheets like microsoft excel and google sheets and loading data from multiple formats  with this introduction you will then learn to perform some basic level data wrangling and cleansing tasks and continue to expand your knowledge of analyzing data through the use of filtering  sorting  and using pivot tables within the spreadsheet  by performing these tasks throughout the course  it will give you an understanding of how spreadsheets can be used as a data analysis tool and understand its limitations  

there is a strong focus on practice and applied learning in this course  with each lab  you will gain hands on experience in manipulating data and begin to understand the important role of spreadsheets  clean and analyze your data faster by understanding functions in the formatting of data  you will then convert your data to a pivot table and learn its features to make your data organized and readable  the final project enables you to show off your newly acquired data analysis skills  by the end of this course you will have worked with several data sets and spreadsheets and demonstrated the basics of cleaning and analyzing data all without having to learn any code  

getting started with excel is made easy in this course  it does not require any prior experience with spreadsheets or coding  nor does it require downloads or installation of any software  all you need is a device with a modern web browser  and ability to create a microsoft account to access excel online at no cost   however if you already have a desktop version of excel  you can follow along quite easily as well "
excourse34,introduction to data analysis,"with this course  you will begin to take the first steps in the world of data analysis  you will see in detail the main concepts and processes that make up this discipline  the main goal of the course is acquisition of knowledge about the mathematical and statistical basics underlying the main ideas and approaches used in data science  this is achieved through setting and solving typical tasks  which a researcher in the field of data science can face in his work  you will get practical skills in working with data analysis tools used in different spheres of human activity  you will be acquainted with the main tasks  methods and basic algorithms  as well as with the spheres of their practical applications  you will know how applied problems of data processing and analysis are being solved  you will be acquainted with the main concepts of artificial neural networks and the ways they are being trained 
"
excourse35,introduction to predictive modeling,"welcome to introduction to predictive modeling  the first course in the university of minnesota  s analytics for decision making specialization 

this course will introduce to you the concepts  processes  and applications of predictive modeling  with a focus on linear regression and time series forecasting models and their practical use in microsoft excel  by the end of the course  you will be able to 

           understand the concepts  processes  and applications of predictive modeling 
           understand the structure of and intuition behind linear regression models 
           be able to fit simple and multiple linear regression models to data  interpret the results  evaluate the goodness of fit  and use fitted models to make predictions 
           understand the problem of overfitting and underfitting and be able to conduct simple model selection 
           understand the concepts  processes  and applications of time series forecasting as a special type of predictive modeling 
           be able to fit several time series forecasting models  e g   exponential smoothing and holt winter  s method  in excel  evaluate the goodness of fit  and use fitted models to make forecasts 
           understand different types of data and how they may be used in predictive models 
           use excel to prepare data for predictive modeling  including exploring data patterns  transforming data  and dealing with missing values 

this is an introductory course to predictive modeling  the course provides a combination of conceptual and hands on learning  during the course  we will provide you opportunities to practice predictive modeling techniques on real world datasets using excel "
excourse36,data analysis using python,"this course provides an introduction to basic data science techniques using python   students are introduced to core concepts like data frames and joining data  and learn how to use data analysis libraries like pandas  numpy  and matplotlib   this course provides an overview of loading  inspecting  and querying real world data  and how to answer basic questions about that data   students will gain skills in data aggregation and summarization  as well as basic data visualization 
"
excourse37,data analysis with r programming,"this course is the seventh course in the google data analytics certificate  these courses will equip you with the skills needed to apply to introductory level data analyst jobs  in this course  you  ll learn about the programming language known as r  you  ll find out how to use rstudio  the environment that allows you to work with r  this course will also cover the software applications and tools that are unique to r  such as r packages  you  ll discover how r lets you clean  organize  analyze  visualize  and report data in new and more powerful ways   current google data analysts will continue to instruct and provide you with hands on ways to accomplish common data analyst tasks with the best tools and resources 

learners who complete this certificate program will be equipped to apply for introductory level jobs as data analysts  no previous experience is necessary 

by the end of this course  you will 
   examine the benefits of using the r programming language 
   discover how to use rstudio to apply r to your analysis  
   explore the fundamental concepts associated with programming in r  
   explore the contents and components of r packages including the tidyverse package 
   gain an understanding of dataframes and their use in r 
   discover the options for generating visualizations in r 
   learn about r markdown for documenting r programming 
"
excourse38,data analysis with python,"learn how to analyze data using python  this course will take you from the basics of python to exploring many different types of data  you will learn how to prepare data for analysis  perform simple statistical analysis  create meaningful data visualizations  predict future trends from data  and more 

topics covered 

1  importing datasets
2  cleaning the data
3  data frame manipulation
4  summarizing the data
5  building machine learning regression models
6  building data pipelines

 data analysis with python will be delivered through lecture  lab  and assignments  it includes following parts 

data analysis libraries  will learn to use pandas  numpy and scipy libraries to work with a sample dataset  we will introduce you to pandas  an open source library  and we will use it to load  manipulate  analyze  and visualize cool datasets  then we will introduce you to another open source library  scikit learn  and we will use some of its machine learning algorithms to build smart models and make cool predictions "
excourse39,excel fundamentals for data analysis,"as data becomes the modern currency  so the ability to analyse the data quickly and accurately has become of paramount importance  excel with its extraordinarily broad range of features and capabilities is one of the most widely used programs for doing this  in the first course of our excel skills for data analysis and visualization specialization  you will learn the fundamentals of excel for data analysis  when you have completed the course  you will be able to use a range of excel tools and functions to clean and prepare data for analysis  automate data analysis with the help of named ranges and tables  and use logical and lookup functions to transform  link and categorise data 

this course will enable you to build a strong foundation in the fundamentals  helping you to be more efficient in your day to day and developing the necessary skills to work with the more advanced techniques used in later courses  to make the content easy to relate to and to personalize the learning experience  we are going to follow zara s journey through the course  who is zara  well  she is no one and everyone  you will find that zara s trials and tribulations sound familiar  and together with zara  you will develop your excel skills along the way    and  importantly  have some fun doing it 

the excel skills for data analytics and visualization courses are the sequel to one of most successful specializations on coursera  excel skills for business  which has attracted hundreds of thousands of learners and top ratings  transform your skills  your confidence  and your opportunities by adding this new set of skills to your repertoire 
"
excourse40,exploratory data analysis for machine learning,"this first course in the ibm machine learning professional certificate introduces you to machine learning and the content of the professional certificate  in this course you will realize the importance of good  quality data  you will learn common techniques to retrieve your data  clean it  apply feature engineering  and have it ready for preliminary analysis and hypothesis testing 

by the end of this course you should be able to 
retrieve data from multiple data sources  sql  nosql databases  apis  cloud 
describe and use common feature selection and feature engineering techniques
handle categorical and ordinal features  as well as missing values
use a variety of techniques for detecting and dealing with outliers
articulate why feature scaling is important and use a variety of scaling techniques
 
who should take this course 
this course targets aspiring data scientists interested in acquiring hands on experience  with machine learning and artificial intelligence in a business setting 
 
what skills should you have 
to make the most out of this course  you should have familiarity with programming on a python development environment  as well as fundamental understanding of calculus  linear algebra  probability  and statistics "
excourse41,introduction to data analysis using excel,the use of excel is widespread in the industry  it is a very powerful data analysis tool and almost all big and small businesses use excel in their day to day functioning  this is an introductory course in the use of excel and is designed to give you a working knowledge of excel with the aim of getting to use it for more advance topics in business statistics later  the course is designed keeping in mind two kinds of learners    those who have very little functional knowledge of excel and those who use excel regularly but at a peripheral level and wish to enhance their skills  the course takes you from basic operations such as reading data into excel using various data formats  organizing and manipulating data  to some of the more advanced functionality of excel  all along  excel functionality is introduced using easy to understand examples which are demonstrated in a way that learners can become comfortable in understanding and applying them 
excourse42,big data analysis  hive  spark sql  dataframes and graphframes,"no doubt working with huge data volumes is hard  but to move a mountain  you have to deal with a lot of small stones  but why strain yourself  using  mapreduce and spark you tackle the issue partially  thus leaving some space for high level tools  stop  struggling to make your big data workflow productive and efficient   make use of the tools we are offering you 

this course will teach you how to 
  warehouse your data efficiently using hive  spark sql and spark datafframes  
  work with large graphs  such as social graphs or networks  
  optimize your spark applications for maximum performance 

precisely  you will master your knowledge in 
  writing and executing hive   spark sql queries 
  reasoning how the queries are translated into actual execution primitives  be it mapreduce jobs or spark transformations  
  organizing your data in hive to optimize disk space usage and execution times 
  constructing spark dataframes and using them to write ad hoc analytical jobs easily 
  processing large graphs with spark graphframes 
  debugging  profiling and optimizing spark application performance "
excourse43,cloud virtualization  containers and apis,"welcome to the second course in the building cloud computing solutions at scale specialization  in this course  you will learn to design cloud native systems with the fundamental building blocks of cloud computing  these building blocks include virtual machines and containers  you will also learn how to build effective microservices using technologies like flask and kubernetes  finally  you will analyze successful patterns in operations including  effective alerts  load testing and kaizen  

this course is ideal for beginners as well as intermediate students interested in applying cloud computing to data science  machine learning and data engineering  students should have beginner level linux and intermediate level python skills  for your project in this course  you build a containerized flask application that is continuously deployed to a cloud platform  amazon web services  aws   azure or google cloud platform  gcp  "
excourse44,alibaba cloud native solutions and container service,"this course demonstrates how to use alibaba cloud container service and container registry service to design and develop architectures related to cloud native applications  services  and security solutions  this course helps you understand the basic concepts of cloud native  the commercial implementation of container technology  and kubernetes technology as well as extra benefits provided by alibaba cloud  this course is intended to prepare users to take the alibaba cloud native aca certification exam    
building containerized applications on aws    this course introduces you to container technologies and how they can be used to modernize your applications  as well as exploring how different aws services can be used to manage and orchestrate those containers 

container technologies have existed for years  and are still gaining popularity  two of the most prevalent options are docker and kubernetes   each with its own distinct set of features  regardless of which technology you choose  one of the biggest challenges with containers is their orchestration  unlike traditional  monolithic applications where you can only scale at a macro level   an executable  for example   containerized applications scale at the container level  when coupled with a microservices approach  each container can contain the code necessary to execute a single task or function  while this provides a number of benefits  a single application can consist of hundreds of containerized microservices  how do you handle starting  stopping  scaling out and scaling in all of these containers 

aws offers a number of services that help with container orchestration  including amazon elastic container service  ecs   amazon elastic kubernetes service  eks   amazon lightsail  and amazon elastic container registry  ecr   throughout this course  expert instructors will dive deep into these services as well as general container technologies and capabilities 

this course uses a combination of video based lectures  delivered by aws technical trainers  demonstrations  and hands on lab exercises to enable you to deploy and manage a containerized application "
excourse45,docker  basics,"the docker basics course will introduce you at a fundamental level to one of the technologies in currently highest demand 

the course takes 5 weeks  the course program includes lectures and videos   you can choose between text and video — whatever fits you best  at the end of each week  you take a test and a practical drill  the fifth training week is devoted to the implementation of the final project 
in this course  you will learn how to work with docker images and volumes  configure the docker daemon and environment variables  forward ports inside a container  and much more  having completed this course  you will be able to work with docker at a basic level and apply it to your projects "
excourse46,machine learning,"machine learning is the science of getting computers to act without being explicitly programmed  in the past decade  machine learning has given us self driving cars  practical speech recognition  effective web search  and a vastly improved understanding of the human genome  machine learning is so pervasive today that you probably use it dozens of times a day without knowing it  many researchers also think it is the best way to make progress towards human level ai  in this class  you will learn about the most effective machine learning techniques  and gain practice implementing them and getting them to work for yourself  more importantly  you ll learn about not only the theoretical underpinnings of learning  but also gain the practical know how needed to quickly and powerfully apply these techniques to new problems  finally  you ll learn about some of silicon valley s best practices in innovation as it pertains to machine learning and ai 

this course provides a broad introduction to machine learning  datamining  and statistical pattern recognition  topics include   i  supervised learning  parametric non parametric algorithms  support vector machines  kernels  neural networks    ii  unsupervised learning  clustering  dimensionality reduction  recommender systems  deep learning    iii  best practices in machine learning  bias variance theory  innovation process in machine learning and ai   the course will also draw from numerous case studies and applications  so that you ll also learn how to apply learning algorithms to building smart robots  perception  control   text understanding  web search  anti spam   computer vision  medical informatics  audio  database mining  and other areas"
excourse47,machine learning for all,"machine learning  often called artificial intelligence or ai  is one of the most exciting areas of technology at the moment  we see daily news stories that herald new breakthroughs in facial recognition technology  self driving cars or computers that can have a conversation just like a real person  machine learning technology is set to revolutionise almost any area of human life and work  and so will affect all our lives  and so you are likely to want to find out more about it  machine learning has a reputation for being one of the most complex areas of computer science  requiring advanced mathematics and engineering skills to understand it  while it is true that working as a machine learning engineer does involve a lot of mathematics and programming  we believe that anyone can understand the basic concepts of machine learning  and given the importance of this technology  everyone should  the big ai breakthroughs sound like science fiction  but they come down to a simple idea  the use of data to train statistical algorithms  in this course you will learn to understand the basic idea of machine learning  even if you don t have any background in math or programming  not only that  you will get hands on and use user friendly tools developed at goldsmiths  university of london to actually do a machine learning project  training a computer to recognise images  this course is for a lot of different people  it could be a good first step into a technical career in machine learning  after all it is always better to start with the high level concepts before the technical details  but it is also great if your role is non technical  you might be a manager or other non technical role in a company that is considering using machine learning  you really need to understand this technology  and this course is a great place to get that understanding  or you might just be following the news reports about ai and interested in finding out more about the hottest new technology of the moment  whoever you are  we are looking forward to guiding you through you first machine learning project 

nb this course is designed to introduce you to machine learning without needing any programming  that means that we don t cover the programming based machine learning tools like python and tensorflow    
introduction to machine learning    this course will provide you a foundational understanding of machine learning models  logistic regression  multilayer perceptrons  convolutional neural networks  natural language processing  etc   as well as demonstrate how these models can solve complex problems in a variety of industries  from medical diagnostics to image recognition to text prediction  in addition  we have designed practice exercises that will give you hands on experience implementing these data science models on data sets  these practice exercises will teach you how to implement machine learning algorithms with pytorch  open source libraries used by leading tech companies in the machine learning field  e g   google  nvidia  cocacola  ebay  snapchat  uber and many more "
excourse48,introduction to machine learning  language processing,t s no secret that machine learning is one of the fastest growing fields in tech  and the google cloud platform has been instrumental in furthering its development  with a host of apis  google cloud has a tool for just about any machine learning job  in this introductory google cloud labs series  you will get hands on practice with machine learning as it applies to language processing by taking labs that will enable you to extract entities from text  and perform sentiment and syntactic analysis as well as use the speech to text api for transcription
excourse49,applied machine learning in python,"this course will introduce the learner to applied machine learning  focusing more on the techniques and methods than on the statistics behind these methods  the course will start with a discussion of how machine learning is different than descriptive statistics  and introduce the scikit learn toolkit through a tutorial  the issue of dimensionality of data will be discussed  and the task of clustering data  as well as evaluating those clusters  will be tackled  supervised approaches for creating predictive models will be described  and learners will be able to apply the scikit learn predictive modelling methods while understanding process issues related to data generalizability  e g  cross validation  overfitting   the course will end with a look at more advanced techniques  such as building ensembles  and practical limitations of predictive models  by the end of this course  students will be able to identify the difference between a supervised  classification  and unsupervised  clustering  technique  identify which technique they need to apply for a particular dataset and need  engineer features to meet that need  and write python code to carry out an analysis  

this course should be taken after introduction to data science in python and applied plotting  charting   data representation in python and before applied text mining in python and applied social analysis in python"
excourse50,build  train  and deploy ml pipelines using bert,"in the second course of the practical data science specialization  you will learn to automate a natural language processing task by building an end to end machine learning pipeline using hugging face s highly optimized implementation of the state of the art bert algorithm with amazon sagemaker pipelines  your pipeline will first transform the dataset into bert readable features and store the features in the amazon sagemaker feature store  it will then fine tune a text classification model to the dataset using a hugging face pre trained model  which has learned to understand the human language from millions of wikipedia documents  finally  your pipeline will evaluate the model s accuracy and only deploy the model if the accuracy exceeds a given threshold 

practical data science is geared towards handling massive datasets that do not fit in your local hardware and could originate from multiple sources  one of the biggest benefits of developing and running data science projects in the cloud is the agility and elasticity that the cloud offers to scale up and out at a minimum cost 

the practical data science specialization helps you develop the practical skills to effectively deploy your data science projects and overcome challenges at each step of the ml workflow using amazon sagemaker  this specialization is designed for data focused developers  scientists  and analysts familiar with the python and sql programming languages and want to learn how to build  train  and deploy scalable  end to end ml pipelines   both automated and human in the loop   in the aws cloud "
excourse51,introduction to machine learning in production,"in the first course of machine learning engineering for production specialization  you will identify the various components and design an ml production system end to end  project scoping  data needs  modeling strategies  and deployment constraints and requirements  and learn how to establish a model baseline  address concept drift  and prototype the process for developing  deploying  and continuously improving a productionized ml application 

understanding machine learning and deep learning concepts is essential  but if you re looking to build an effective ai career  you need production engineering capabilities as well  machine learning engineering for production combines the foundational concepts of machine learning with the functional expertise of modern software development and engineering roles to help you develop production ready skills  "
excourse52,machine learning data lifecycle in production,"in the second course of machine learning engineering for production specialization  you will build data pipelines by gathering  cleaning  and validating datasets and assessing data quality  implement feature engineering  transformation  and selection with tensorflow extended and get the most predictive power out of your data  and establish the data lifecycle by leveraging data lineage and provenance metadata tools and follow data evolution with enterprise data schemas 

understanding machine learning and deep learning concepts is essential  but if you re looking to build an effective ai career  you need production engineering capabilities as well  machine learning engineering for production combines the foundational concepts of machine learning with the functional expertise of modern software development and engineering roles to help you develop production ready skills "
excourse53,deploying machine learning models in production,"in the fourth course of machine learning engineering for production specialization  you will learn how to deploy ml models and make them available to end users  you will build scalable and reliable hardware infrastructure to deliver inference requests both in real time and batch depending on the use case  you will also implement workflow automation and progressive delivery that complies with current mlops practices to keep your production system running  additionally   you will continuously monitor your system to detect model decay  remediate performance drops  and avoid system failures so it can continuously operate at all times   

understanding machine learning and deep learning concepts is essential  but if you re looking to build an effective ai career  you need production engineering capabilities as well  machine learning engineering for production combines the foundational concepts of machine learning with the functional expertise of modern software development and engineering roles to help you develop production ready skills 

week 1  model serving introduction
week 2  model serving patterns and infrastructures
week 3  model management and delivery
week 4  model monitoring and logging"
excourse54,exploratory data analysis for machine learning,"this first course in the ibm machine learning professional certificate introduces you to machine learning and the content of the professional certificate  in this course you will realize the importance of good  quality data  you will learn common techniques to retrieve your data  clean it  apply feature engineering  and have it ready for preliminary analysis and hypothesis testing 

by the end of this course you should be able to 
retrieve data from multiple data sources  sql  nosql databases  apis  cloud 
describe and use common feature selection and feature engineering techniques
handle categorical and ordinal features  as well as missing values
use a variety of techniques for detecting and dealing with outliers
articulate why feature scaling is important and use a variety of scaling techniques
 
who should take this course 
this course targets aspiring data scientists interested in acquiring hands on experience  with machine learning and artificial intelligence in a business setting 
 
what skills should you have 
to make the most out of this course  you should have familiarity with programming on a python development environment  as well as fundamental understanding of calculus  linear algebra  probability  and statistics "
excourse55,advanced computer vision with tensorflow,"in this course  you will 

a  explore image classification  image segmentation  object localization  and object detection  apply transfer learning to object localization and detection 
b  apply object detection models such as regional cnn and resnet 50  customize existing models  and build your own models to detect  localize  and label your own rubber duck images 
c  implement image segmentation using variations of the fully convolutional network  fcn  including u net and d  mask rcnn to identify and detect numbers  pets  zombies  and more 
d  identify which parts of an image are being used by your model to make its predictions using class activation maps and saliency maps and apply these ml interpretation methods to inspect and improve the design of a famous network  alexnet "
excourse56,deep learning applications for computer vision,"this course can be taken for academic credit as part of cu boulder s master of science in data science  ms ds  degree offered on the coursera platform  the ms ds is an interdisciplinary degree that brings together faculty from cu boulder s departments of applied mathematics  computer science  information science  and others  with performance based admissions and no application process  the ms ds is ideal for individuals with a broad range of undergraduate education and or professional experience in computer science  information science  mathematics  and statistics 

in this course  you ll be learning about computer vision as a field of study and research  first we ll be exploring several computer vision tasks and suggested approaches  from the classic computer vision perspective  then we ll introduce deep learning methods and apply them to some of the same problems  we will analyze the results and discuss advantages and drawbacks of both types of methods  we ll use tutorials to let you explore hands on some of the modern machine learning tools and software libraries  examples of computer vision tasks where deep learning can be applied include  image classification  image classification with localization  object detection  object segmentation  facial recognition  and activity or pose estimation"
excourse57,deep learning in computer vision,"deep learning added a huge boost to the already rapidly developing field of computer vision  with deep learning  a lot of new applications of computer vision techniques have been introduced and are now becoming parts of our everyday lives  these include face recognition and indexing  photo stylization or machine vision in self driving cars  

the goal of this online course is to introduce students to computer vision  starting from basics and then turning to more modern deep learning models  we will cover both image and video recognition  including image classification and annotation  object recognition and image search  various object detection techniques  motion estimation  object tracking in video  human action recognition  and finally image stylization  editing and new image generation  in the course project  students will learn how to build face recognition and manipulation system to understand the internal mechanics of this technology  probably the most renown and often demonstrated in movies and tv shows example of computer vision and ai"
excourse58,computer vision basics,"by the end of this course  learners will understand what computer vision is  as well as its mission of making computers see and interpret the world as humans do  by learning core concepts of the field and receiving an introduction to human vision capabilities  they are equipped to identify some key application areas of computer vision and understand the digital imaging process  the course covers crucial elements that enable computer vision  digital signal processing  neuroscience and artificial intelligence  topics include color  light and image formation  early  mid  and high level vision  and mathematics essential for computer vision  learners will be able to apply mathematical techniques to complete computer vision tasks  

this course is ideal for anyone curious about or interested in exploring the concepts of computer vision  it is also useful for those who desire a refresher course in mathematical concepts of computer vision  learners should have basic programming skills and experience  understanding of for loops  if else statements   specifically in matlab  mathworks provides the basics here  https   www mathworks com learn tutorials matlab onramp html   learners should also be familiar with the following  basic linear algebra  matrix vector operations and notation   3d co ordinate systems and transformations  basic calculus  derivatives and integration  and basic probability  random variables "
excourse59,fundamentals of digital image and video processing,"in this class you will learn the basic principles and tools used to process images and videos  and how to apply them in solving practical problems of commercial and scientific interests 

digital images and videos are everywhere these days – in thousands of scientific  e g   astronomical  bio medical   consumer  industrial  and artistic applications  moreover they come in a wide range of the electromagnetic spectrum   from visible light and infrared to gamma rays and beyond  the ability to process image and video signals is therefore an incredibly important skill to master for engineering science students  software developers  and practicing scientists    digital image and video processing continues to enable the multimedia technology revolution we are experiencing today  some important examples of image and video processing include the removal of degradations images suffer during acquisition  e g   removing blur from a picture of a fast moving car   and the compression and transmission of images and videos  if you watch videos online  or share photos via a social media website  you use this everyday    for economical storage and efficient transmission  

this course will cover the fundamentals of image and video processing   we will provide a mathematical framework to describe and analyze images and videos as two  and three dimensional signals in the spatial  spatio temporal  and frequency domains  in this class not only will you learn the theory behind fundamental processing tasks including image video enhancement  recovery  and compression   but you will also learn how to perform these key processing tasks in practice using state of the art techniques and tools  we will introduce and use a wide variety of such tools – from optimization toolboxes to statistical techniques  emphasis on the special role sparsity plays in modern image and video processing will also be given   in all cases  example images and videos pertaining to specific application domains will be utilized"
excourse60,introduction to tensorflow for artificial intelligence  machine learning  and deep learning,"if you are a software developer who wants to build scalable ai powered algorithms  you need to understand how to use the tools to build them  this course is part of the upcoming machine learning in tensorflow specialization and will teach you best practices for using tensorflow  a popular open source framework for machine learning  

the machine learning course and deep learning specialization from andrew ng teach the most important and foundational principles of machine learning and deep learning  this new deeplearning ai tensorflow specialization teaches you how to use tensorflow to implement those principles so that you can start building and applying scalable models to real world problems  to develop a deeper understanding of how neural networks work  we recommend that you take the deep learning specialization"
excourse61,convolutional neural networks in tensorflow,"if you are a software developer who wants to build scalable ai powered algorithms  you need to understand how to use the tools to build them  this course is part of the upcoming machine learning in tensorflow specialization and will teach you best practices for using tensorflow  a popular open source framework for machine learning 

in course 2 of the deeplearning ai tensorflow specialization  you will learn advanced techniques to improve the computer vision model you built in course 1  you will explore how to work with real world images in different shapes and sizes  visualize the journey of an image through convolutions to understand how a computer “sees” information  plot loss and accuracy  and explore strategies to prevent overfitting  including augmentation and dropout  finally  course 2 will introduce you to transfer learning and how learned features can be extracted from models  

the machine learning course and deep learning specialization from andrew ng teach the most important and foundational principles of machine learning and deep learning  this new deeplearning ai tensorflow specialization teaches you how to use tensorflow to implement those principles so that you can start building and applying scalable models to real world problems  to develop a deeper understanding of how neural networks work  we recommend that you take the deep learning specialization"
excourse62,introduction to data science in python,"this course will introduce the learner to the basics of the python programming environment  including fundamental python programming techniques such as lambdas  reading and manipulating csv files  and the numpy library  the course will introduce data manipulation and cleaning techniques using the popular python pandas data science library and introduce the abstraction of the series and dataframe as the central data structures for data analysis  along with tutorials on how to use functions such as groupby  merge  and pivot tables effectively  by the end of this course  students will be able to take tabular data  clean it  manipulate it  and run basic inferential statistical analyses  

this course should be taken before any of the other applied data science with python courses  applied plotting  charting   data representation in python  applied machine learning in python  applied text mining in python  applied social network analysis in python"
excourse63,a crash course in data science,"by now you have definitely heard about data science and big data  in this one week class  we will provide a crash course in what these terms mean and how they play a role in successful organizations  this class is for anyone who wants to learn what all the data science action is about  including those who will eventually need to manage data scientists  the goal is to get you up to speed as quickly as possible on data science without all the fluff  we ve designed this course to be as convenient as possible without sacrificing any of the essentials 

this is a focused course designed to rapidly get you up to speed on the field of data science  our goal was to make this as convenient as possible for you without sacrificing any essential content  we ve left the technical information aside so that you can focus on managing your team and moving it forward 

after completing this course you will know  

1  how to describe the role data science plays in various contexts
2  how statistics  machine learning  and software engineering play a role in data science
3  how to describe the structure of a data science project
4  know the key terms and tools used by data scientists
5  how to identify a successful and an unsuccessful data science project
3  the role of a data science manager"
excourse64,data science in real life,"have you ever had the perfect data science experience  the data pull went perfectly  there were no merging errors or missing data  hypotheses were clearly defined prior to analyses  randomization was performed for the treatment of interest  the analytic plan was outlined prior to analysis and followed exactly  the conclusions were clear and actionable decisions were obvious  has that every happened to you  of course not  data analysis in real life is messy  how does one manage a team facing real data analyses  in this one week course  we contrast the ideal with what happens in real life  by contrasting the ideal  you will learn key concepts that will help you manage real life analyses  

this is a focused course designed to rapidly get you up to speed on doing data science in real life  our goal was to make this as convenient as possible for you without sacrificing any essential content  we ve left the technical information aside so that you can focus on managing your team and moving it forward 

after completing this course you will know how to 

1  describe the “perfect” data science experience
2  identify strengths and weaknesses in experimental designs
3  describe possible pitfalls when pulling   assembling data and learn solutions for managing data pulls 
4  challenge statistical modeling assumptions and drive feedback to data analysts
5  describe common pitfalls in communicating data analyses
6  get a glimpse into a day in the life of a data analysis manager 

the course will be taught at a conceptual level for active managers of data scientists and statisticians   some key concepts being discussed include 
1  experimental design  randomization  a b testing
2  causal inference  counterfactuals  
3  strategies for managing data quality 
4  bias and confounding
5  contrasting machine learning versus classical statistical inference"
excourse65,data science fundamentals for data analysts,"in this course we re going to guide you through the fundamental building blocks of data science  one of the fastest growing fields in the world  

with the help of our industry leading data scientists  we ve designed this course to build ready to apply data science skills in just 15 hours of learning  first  we ll give you a quick introduction to data science   what it is and how it is used to solve real world problems  for the rest of the course  we ll teach you the skills you need to apply foundational data science concepts and techniques to solve these real world problems  

by the end of this course  you ll be able to leverage your existing data analysis skills to design  execute  assess  and communicate the results of your very own data science projects    
data science capstone    the capstone project class will allow students to create a usable public data product that can be used to show your skills to potential employers  projects will be drawn from real world problems and will be conducted with industry  government  and academic partners "
excourse66,executive data science capstone,the executive data science capstone  the specialization s culminating project  is an opportunity for people who have completed all four eds courses to apply what they ve learned to a real world scenario developed in collaboration with zillow  a data driven online real estate and rental marketplace  and datacamp  a web based platform for data science programming  your task will be to lead a virtual data science team and make key decisions along the way to demonstrate that you have what it takes to shepherd a complex analysis project from start to finish   for the final project  you will prepare and submit a presentation  which will be evaluated and graded by your fellow capstone participants
excourse67,introduction to big data,"interested in increasing your knowledge of the big data landscape   this course is for those new to data science and interested in understanding why the big data era has come to be   it is for those who want to become conversant with the terminology and the core concepts behind big data problems  applications  and systems   it is for those who want to start thinking about how big data might be useful in their business or career   it provides an introduction to one of the most common frameworks  hadoop  that has made big data analysis easier and more accessible    increasing the potential for data to transform our world 

at the end of this course  you will be able to 

  describe the big data landscape including examples of real world big data problems including the three key sources of big data  people  organizations  and sensors  

  explain the v s of big data  volume  velocity  variety  veracity  valence  and value  and why each impacts data collection  monitoring  storage  analysis and reporting 

  get value out of big data by using a 5 step process to structure your analysis  

  identify what are and what are not big data problems and be able to recast big data problems as data science questions 

  provide an explanation of the architectural components and programming models used for scalable big data analysis 

  summarize the features and value of core hadoop stack components including the yarn resource and job management system  the hdfs file system and the mapreduce programming model 

  install and run a program using hadoop 

this course is for those new to data science   no prior programming experience is needed  although the ability to install applications and utilize a virtual machine is necessary to complete the hands on assignments "
excourse68,big data modeling and management systems,"once you ve identified a big data issue to analyze  how do you collect  store and organize your data using big data solutions   in this course  you will experience various data genres and management tools appropriate for each   you will be able to describe the reasons behind the evolving plethora of new big data platforms from the perspective of big data management systems and analytical tools   through guided hands on tutorials  you will become familiar with techniques using real time and semi structured data examples   systems and tools discussed include  asterixdb  hp vertica  impala  neo4j  redis  sparksql  this course provides techniques to extract value from existing untapped data sources and discovering new data sources 

at the end of this course  you will be able to 
   recognize different data elements in your own work and in everyday life problems
   explain why your team needs to design a big data infrastructure plan and information system design
   identify the frequent data operations required for various types of data
   select a data model to suit the characteristics of your data 
   apply techniques to handle streaming data
   differentiate between a traditional database management system and a big data management system
   appreciate why there are so many data management systems
   design a big data information system for an online game company

this course is for those new to data science   completion of intro to big data is recommended   no prior programming experience is needed  although the ability to install applications and utilize a virtual machine is necessary to complete the hands on assignments   refer to the specialization technical requirements for complete hardware and software specifications    
big data integration and processing    at the end of the course  you will be able to 

 retrieve data from example database and big data management systems 
 describe the connections between data management operations and the big data processing patterns needed to utilize them in large scale analytical applications
 identify when a big data problem needs data integration
 execute simple big data integration and processing on hadoop and spark platforms"
excourse69,machine learning with big data,"want to make sense of the volumes of data you have collected   need to incorporate data driven decisions into your process   this course provides an overview of machine learning techniques to explore  analyze  and leverage data   you will be introduced to tools and algorithms you can use to create machine learning models that learn from data  and to scale those models up to big data problems 

at the end of the course  you will be able to 
design an approach to leverage data using the steps in the machine learning process 
apply machine learning techniques to explore and prepare data for modeling 
identify the type of machine learning problem in order to apply the appropriate set of techniques 
	construct models that learn from data using widely available open source tools 
	analyze big data problems using scalable machine learning algorithms on spark "
excourse70,big data   capstone project,welcome to the capstone project for big data  in this culminating project  you will build a big data ecosystem using tools and methods form the earlier courses in this specialization  you will analyze a data set simulating big data generated from a large number of users who are playing our imaginary game     catch the pink flamingo      during the five week capstone project  you will walk through the typical big data science steps for acquiring  exploring  preparing  analyzing  and reporting  in the first two weeks  we will introduce you to the data set and guide you through some exploratory analysis using tools such as splunk and open office  then we will move into more challenging big data problems requiring the more advanced tools you have learned including knime  spark s mllib and gephi  finally  during the fifth and final week  we will show you how to bring it all together to create engaging and compelling reports and slide presentations  as a result of our collaboration with splunk  a software company focus on analyzing machine generated big data  learners with the top projects will be eligible to present to splunk and meet splunk recruiters and engineering leadership
excourse71,big data essentials  hdfs  mapreduce and spark rdd,"have you ever heard about such technologies as hdfs  mapreduce  spark  always wanted to learn these new tools but missed concise starting material  don t miss this course either 

in this 6 week course you will 
  learn some basic technologies of the modern big data landscape  namely  hdfs  mapreduce and spark 
  be guided both through systems internals and their applications 
  learn about distributed file systems  why they exist and what function they serve 
  grasp the mapreduce framework  a workhorse for many modern big data applications 
  apply the framework to process texts and solve sample business cases 
  learn about spark  the next generation computational framework 
  build a strong understanding of spark basic concepts 
  develop skills to apply these tools to creating solutions in finance  social networks  telecommunications and many other fields"
excourse72,foundations for big data analysis with sql,"in this course  you ll get a big picture view of using sql for big data  starting with an overview of data  database systems  and the common querying language  sql   then you ll learn the characteristics of big data and sql tools for working on big data platforms  you ll also install an exercise environment  virtual machine  to be used through the specialization courses  and you ll have an opportunity to do some initial exploration of databases and tables in that environment 

by the end of the course  you will be able to
 distinguish operational from analytic databases  and understand how these are applied in big data 
 understand how database and table design provides structures for working with data 
 appreciate how differences in volume and variety of data affects your choice of an appropriate database system 
recognize the features and benefits of sql dialects designed to work with big data systems for storage and analysis  and 
 explore databases and tables in a big data platform"
excourse73,analyzing big data with sql,"in this course  you ll get an in depth look at the sql select statement and its main clauses  the course focuses on big data sql engines apache hive and apache impala  but most of the information is applicable to sql with traditional rdbms as well  the instructor explicitly addresses differences for mysql and postgresql 

by the end of the course  you will be able to
• explore and navigate databases and tables using different tools 
• understand the basics of select statements 
• understand how and why to filter results 
• explore grouping and aggregation to answer analytic questions 
• work with sorting and limiting results  and 
• combine multiple tables in different ways "
excourse74,fundamentals of big data,welcome to fundamentals of big data  the fourth course of the key technologies of data analytics specialization  by enrolling in this course  you are taking the next step in your career in data analytics  this course is the fourth of a series that aims to prepare you for a role working in data analytics  in this course  you will be introduced to many of the core concepts of big data  you will learn about the primary systems used in big data  we ll go through phases of a common big data life cycle  this course covers a wide variety of topics that are critical for understanding big data and are designed to give you an introduction and overview as you begin to build relevant knowledge and skills
excourse75,hadoop platform and application framework,this course is for novice programmers or business people who would like to understand the core tools used to wrangle and analyze big data  with no prior experience  you will have the opportunity to walk through hands on examples with hadoop and spark frameworks  two of the most common in the industry  you will be comfortable explaining the specific components and basic processes of the hadoop architecture  software stack  and execution environment    in the assignments you will be guided in how data scientists apply the important concepts and techniques such as map reduce that are used to solve fundamental problems in big data   you ll feel empowered to have conversations about big data and the data analysis process
excourse76,working with big data,"by the end of this project  you will set up an environment for big data development using visual studio code  mongodb and apache spark  you will then use the environment to process a large dataset from noaa showing hourly precipitation rates for a ten year period from the state of wisconsin 
mongodb is a widely used nosql database well suited for very large datasets or big data  it is highly scalable and adaptable as well  apache spark is used for efficient in memory processing of big data "
excourse77,natural language processing with attention models,"in course 4 of the natural language processing specialization  you will 

a  translate complete english sentences into german using an encoder decoder attention model 
b  build a transformer model to summarize text  
c  use t5 and bert models to perform question answering  and
d  build a chatbot using a reformer model  


by the end of this specialization  you will have designed nlp applications that perform question answering and sentiment analysis  created tools to translate languages and summarize text  and even built a chatbot    

learners should have a working knowledge of machine learning  intermediate python including experience with a deep learning framework  e g   tensorflow  keras   as well as proficiency in calculus  linear algebra  and statistics  please make sure that you ve completed course 3   natural language processing with sequence models   before starting this course 
   
this specialization is designed and taught by two experts in nlp  machine learning  and deep learning  younes bensouda mourri is an instructor of ai at stanford university who also helped build the deep learning specialization     kaiser is a staff research scientist at google brain and the co author of tensorflow  the tensor2tensor and trax libraries  and the transformer paper"
excourse78,natural language processing with sequence models,"in course 3 of the natural language processing specialization  you will 

a  train a neural network with glove word embeddings to perform sentiment analysis of tweets 
b  generate synthetic shakespeare text using a gated recurrent unit  gru  language model 
c  train a recurrent neural network to perform named entity recognition  ner  using lstms with linear layers  and 
d  use so called ‘siamese  lstm models to compare questions in a corpus and identify those that are worded differently but have the same meaning 


by the end of this specialization  you will have designed nlp applications that perform question answering and sentiment analysis  created tools to translate languages and summarize text  and even built a chatbot "
excourse79,natural language processing with probabilistic models,"in course 2 of the natural language processing specialization  you will 

a  create a simple auto correct algorithm using minimum edit distance and dynamic programming 
b  apply the viterbi algorithm for part of speech  pos  tagging  which is vital for computational linguistics 
c  write a better auto complete algorithm using an n gram language model  and 
d  write your own word2vec model that uses a neural network to compute word embeddings using a continuous bag of words model"
excourse80,r programming,in this course you will learn how to program in r and how to use r for effective data analysis  you will learn how to install and configure software necessary for a statistical programming environment and describe generic programming language concepts as they are implemented in a high level statistical language  the course covers practical issues in statistical computing which includes programming in r  reading data into r  accessing r packages  writing r functions  debugging  profiling r code  and organizing and commenting r code  topics in statistical data analysis will provide working examples
excourse81,data analysis with r programming,"this course is the seventh course in the google data analytics certificate  these courses will equip you with the skills needed to apply to introductory level data analyst jobs  in this course  you ll learn about the programming language known as r  you ll find out how to use rstudio  the environment that allows you to work with r  this course will also cover the software applications and tools that are unique to r  such as r packages  you ll discover how r lets you clean  organize  analyze  visualize  and report data in new and more powerful ways   current google data analysts will continue to instruct and provide you with hands on ways to accomplish common data analyst tasks with the best tools and resources 

learners who complete this certificate program will be equipped to apply for introductory level jobs as data analysts  no previous experience is necessary 

by the end of this course  you will 
   examine the benefits of using the r programming language 
   discover how to use rstudio to apply r to your analysis  
   explore the fundamental concepts associated with programming in r  
   explore the contents and components of r packages including the tidyverse package 
   gain an understanding of dataframes and their use in r 
   discover the options for generating visualizations in r 
   learn about r markdown for documenting r programming"
excourse82,getting started with data visualization in r,"data visualization is a critical skill for anyone that routinely using quantitative data in his or her work   which is to say that data visualization is a tool that almost every worker needs today  one of the critical tools for data visualization today is the r statistical programming language  especially in conjunction with the tidyverse software packages  r has become an extremely powerful and flexible platform for making figures  tables  and reproducible reports  however  r can be intimidating for first time users  and there are so many resources online that it can be difficult to sort through without guidance 

to fill that need  this course is intended for learners who have little or no experience with r but who are looking for an introduction to this tool  by the end of this course  students will be able to import data into r  manipulate that data using tools from the popular tidyverse package  and make simple reports using r markdown  the course is designed for students with good basic computing skills  but limited if any experience with programming"
excourse83,introduction to probability and data with r,this course introduces you to sampling and exploring data  as well as basic probability theory and bayes  rule  you will examine various types of sampling methods  and discuss how such methods can impact the scope of inference  a variety of exploratory data analysis techniques will be covered  including numeric summary statistics and basic data visualization  you will be guided through installing and using r and rstudio  free statistical software   and will use this software for lab exercises and a final project  the concepts and techniques in this course will serve as building blocks for the inference and modeling courses in the specialization
excourse84,using r for regression and machine learning in investment ,"in this course  the instructor will discuss various uses of regression in investment problems  and she will extend the discussion to logistic  lasso  and ridge regressions  at the same time  the instructor will introduce various concepts of machine learning  you can consider this course as the first step toward using machine learning methodologies in solving investment problems  the course will cover investment analysis topics  but at the same time  make you practice it using r programming  this course s focus is to train you to use various regression methodologies for investment management that you might need to do in your job every day and make you ready for more advanced topics in machine learning  

the course is designed with the assumption that most students already have a little bit of knowledge in financial economics and r programming  students are expected to have heard about stocks and bonds and balance sheets  earnings  etc   and know the introductory statistics level  such as mean  median  distribution  regression  etc  students are also expected to know of the instructors  1st course   fundamental of data driven investment  

the instructor will explain the detail of r programming  it will be an excellent course for you to improve your programming skills but you must have basic knowledge in r  if you are very good at r programming  it will provide you with an excellent opportunity to practice again with finance and investment examples"
excourse85,data visualization in r with ggplot2,"data visualization is a critical skill for anyone that routinely using quantitative data in his or her work   which is to say that data visualization is a tool that almost every worker needs today  one of the critical tools for data visualization today is the r statistical programming language  especially in conjunction with the tidyverse software packages  r has become an extremely powerful and flexible platform for making figures  tables  and reproducible reports  however  r can be intimidating for first time users  and there are so many resources online that it can be difficult to sort through without guidance 

this course is the second in a specialization in data visualization offered by johns hopkins  it is intended for learners who have either have some experience with r and data wrangling in the tidyverse or have taken the previous course in the specialization  the focus in this course learning to use ggplot2 to make a variety of visualizations and to polish those visualizations using tools within ggplot as well as vector graphics editing software  the course will not go into detail about how the data management works behind the scenes"
excourse86,the r programming environment,this course provides a rigorous introduction to the r programming language  with a  particular focus on using r for software development in a data science setting  whether you are part of a data science team or working individually within a community of developers  this course will give you the knowledge of r needed to make useful contributions in those settings  as the first course in the specialization  the course provides the essential foundation of r needed for the following courses  we cover basic r concepts and language fundamentals  key concepts like tidy data and related     tidyverse     tools  processing and manipulation of complex and large datasets  handling textual data  and basic data science tasks  upon completing this course  learners will have fluency at the r console and will be able to create tidy datasets from a wide range of possible data sources
excourse87,html  css  and javascript for web developers,"do you realize that the only functionality of a web application that the user directly interacts with is through the web page  implement it poorly and  to the user  the server side becomes irrelevant  today s user expects a lot out of the web page  it has to load fast  expose the desired service  and be comfortable to view on all devices  from a desktop computers to tablets and mobile phones 

in this course  we will learn the basic tools that every web page coder needs to know  we will start from the ground up by learning how to implement modern web pages with html and css  we will then advance to learning how to code our pages such that its components rearrange and resize themselves automatically based on the size of the user s screen  you ll be able to code up a web page that will be just as useful on a mobile phone as on a desktop computer  no “pinch and zoom” required  last but certainly not least  we will get a thorough introduction to the most ubiquitous  popular  and incredibly powerful language of the web  javascript  using javascript  you will be able to build a fully functional web application that utilizes ajax to expose server side functionality and data to the end use"
excourse88,javascript basics,"this course introduces the programming language javascript and shows the websites that include the type of interactions students will eventually be able to develop   learners will understand the importance of how javascript was developed and why such history impacts the way javascript is currently written and in future releases   

learners will write their first scripts  have their html and css skills assessed  create variables and arrays and assign values to them   if student s skills are lacking  resources and recommendations are provided to improve these skills  there is ample opportunity for students to practice these first  core skills"
excourse89,javascript  jquery  and json,"in this course  we ll look at the javascript language  and how it supports the object oriented pattern  with a focus on the unique aspect of how javascript approaches oo  we ll explore a brief introduction to the jquery library  which is widely used to do in browser manipulation of the document object model  dom  and event handling  you ll also learn more about javascript object notation  json   which is commonly used as a syntax to exchange data between code running on the server  i e  in php  and code running in the browser  javascript jquery  

it is assumed that learners have already taken the building web applications and building database applications in php courses in this specialization "
excourse90,programming foundations with javascript  html and css,"learn foundational programming concepts  e g   functions  for loops  conditional statements  and how to solve problems like a programmer  in addition  learn basic web development as you build web pages using html  css  javascript  by the end of the course  will create a web page where others can upload their images and apply image filters that you create 

after completing this course  you will be able to 
1  think critically about how to solve a problem using programming 
2  write javascript programs using functions  for loops  and conditional statements 
3  use html to construct a web page with paragraphs  divs  images  links  and lists 
4  add styles to a web page with css ids and classes  and
5  make a web page interactive with javascript commands like alert  onclick  onchange  adding input features like an image canvas  button  and slider"
excourse91,front end web development with react,"this course explores javascript based front end application development  and in particular the react library  currently ver  16 3   this course will use javascript es6 for developing react application  you will also get an introduction to the use of reactstrap for bootstrap 4 based responsive ui design  you will be introduced to various aspects of react components  you will learn about react router and its use in developing single page applications  you will also learn about designing controlled forms  you will be introduced to the flux architecture and redux  you will explore various aspects of redux and use it to develop react redux powered applications  you will then learn to use fetch for client server communication and the use of rest api on the server side  a quick tour through react animation support and testing rounds off the course  you must have preferably completed the previous course in the specialization on bootstrap 4  or have a working knowledge of bootstrap 4 to be able to navigate this course  also a good working knowledge of javascript  especially es 5 is strongly recommended 

at the end of this course you will 

  be familiar with client side javascript application development and the react library
  be able to implement single page applications in react
  be able to use various react features including components and forms
  be able to implement a functional front end web application using react
  be able to use reactstrap for designing responsive react applications
  be able to use redux to design the architecture for a react redux application"
excourse92,introduction to web development,"this course is designed to start you on a path toward future studies in web development and design  no matter how little experience or technical knowledge you currently have  the web is a very big place  and if you are the typical internet user  you probably visit several websites every day  whether for business  entertainment or education  but have you ever wondered how these websites actually work  how are they built  how do browsers  computers  and mobile devices interact with the web  what skills are necessary to build a website  with almost 1 billion websites now on the internet  the answers to these questions could be your first step toward a better understanding of the internet and developing a new set of internet skills   

by the end of this course you ll be able to describe the structure and functionality of the world wide web  create dynamic web pages using a combination of html  css  and javascript  apply essential programming language concepts when creating html forms  select an appropriate web hosting service  and publish your webpages for the world to see  finally  you ll be able to develop a working model for creating your own personal or business websites in the future and be fully prepared to take the next step in a more advanced web development or design course or specialization"
excourse93,interactivity with javascript and jquery,this course is the third in our javascript for beginners specialization  the scripts will become more complex and introduce more complex jquery plugins  you will have several challenges to practice your skills throughout the course  the course objectives include how to identify objects in javascript  create new objects and populate them with data  manipulate objects by adding  modifying and deleting data in objects  manipulate the dom based on the data in objects  identify and articulate how multiple functions work together to create a more complex program  and identify processes for breaking larger programs into smaller  more manageable pieces 
